{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining all the constants required (copying them from Matlab and adjusting syntax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dolfin import *\n",
    "\n",
    "#importing mshr for all mesh functions\n",
    "import mshr as mshr\n",
    "\n",
    "# Use SymPy to compute f from the manufactured solution u\n",
    "import sympy as sym\n",
    "\n",
    "#Option to avoid printing redundant information from each core when running the code in parallel from\n",
    "#a python (.py) script obtained from the jupyter notebook.\n",
    "parallel_run = False\n",
    "\n",
    "#List of commands that shouldnt run when using the python file rather than the notebook\n",
    "if parallel_run == False:\n",
    "\n",
    "    #have to define where to put plots BEFORE importing matplotlib\n",
    "    %matplotlib notebook\n",
    "\n",
    "#Importing matplotlib to plot the results\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#Importing numpy to work with arrays\n",
    "import numpy as np\n",
    "\n",
    "#Importing time to compute how long each segment takes\n",
    "import time\n",
    "\n",
    "#importing regex to change every instance of radius_tot so we change the ones in the C++ code\n",
    "#at the same time too\n",
    "import re\n",
    "\n",
    "#varname gives the name of the variable as a string\n",
    "from varname import varname\n",
    "\n",
    "#Needed to use the 3D scatter\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "#Importing the decimal package to be able to specify arbitrary accuracy, needed e.g. when\n",
    "#calculating the jacobian for the lensing\n",
    "from decimal import *\n",
    "\n",
    "#Increasing the width of the notebook (visual difference only)\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "#Needed if want to use the adapt function for mesh refinement, see:\n",
    "#https://fenicsproject.org/qa/6719/using-adapt-on-a-meshfunction-looking-for-a-working-example/\n",
    "parameters[\"refinement_algorithm\"] = \"plaza_with_parent_facets\"\n",
    "\n",
    "#Importing all quantities, constants etc used in the calculations\n",
    "from MONDquantities import *\n",
    "\n",
    "#Importing the functions I made from the MONDfunctions file\n",
    "from MONDfunctions import *\n",
    "\n",
    "#Importing all classes I created\n",
    "from MONDclasses import *\n",
    "\n",
    "#Importing all expressions for weak forms, initial guesses/BCs and sources\n",
    "from MONDexpressions import *\n",
    "\n",
    "c = 2.998*10**8\n",
    "G = 6.674*10**(-11) \n",
    "a0 = 1.2*10**(-10) \n",
    "#Mass of the sun\n",
    "ms = 1.989*10**30 \n",
    "mgd = 10**12*ms \n",
    "ly = 9.461*10**15 \n",
    "kp = 3261.56*ly \n",
    "kpm = 20*kp \n",
    "au = 0.0000158*ly \n",
    "lst = 200*au \n",
    "lsu = 50*au \n",
    "lg = 52850*ly \n",
    "lgu = 40*10**3*ly \n",
    "lgb = 3*kp \n",
    "rs = 0.00465*au \n",
    "#Mass of the milky way\n",
    "mgb = 1.1*6.6*10**10*ms\n",
    "#Mass of the virgo cluster (inlcudes dark matter)\n",
    "mass_virgo = 10**15*ms\n",
    "#Mass of the coma cluster (without dark matter, from the Brownstein 2006 paper)\n",
    "mass_coma = 3.81*10**14*ms\n",
    "#Radius of the coma cluster\n",
    "radius_coma = 3000*kp\n",
    "\n",
    "#Here replacing the mass of the galaxy with that of virgo, since we're working on the cluster scale\n",
    "mgb = mass_coma\n",
    "\n",
    "#Setting domain_size to the radius of the Virgo Cluster, 2.3 Mpc\n",
    "domain_size = radius_coma\n",
    "#Smallest size of a galaxy in Virgo has a radius = r_Virgo/250, so that's the resolution we need\n",
    "radius_tot = domain_size/5\n",
    "#Origin at (0,0,0) for the mesh\n",
    "origin = Point(0,0,0)\n",
    "radius_refine = radius_tot\n",
    "volume_out = 4/3*pi*(radius_tot**3)\n",
    "#Standard deviation for coarse mass distribution and location of peaks. domain_size/3 corresponds to have\n",
    "#99.7% of the mass distribution inside the domain. Dividing that by some other factor makes it less \n",
    "#likely that the masses will be outside the domain and throw an error\n",
    "stand_dev = domain_size/3/1.5\n",
    "#Standard deviation for the gaussian peaks themselves, Radius tot/3 so 99.7% of the mass is inside the \n",
    "#equivalent dirac delta made with a uniform sphere\n",
    "stand_dev_peak = radius_tot/3\n",
    "mesh_resolution = 17\n",
    "#Coefficient for GEA changing the potential based on how spherically symmetric the mass distribution is\n",
    "c_2 = -1.8\n",
    "#Coefficient for GEA giving the magnitude of the K^3/2 term in the Lagrangian, which determines the\n",
    "#interpolation function\n",
    "beta = 6/sqrt(2+c_2)\n",
    "#Resolution of the uniform grid onto which we interpolate our results to have nicer plots\n",
    "plot_resolution = mesh_resolution\n",
    "#Size of the mesh for plotting. Should be bigger than the normal one or some points might be outside its domain\n",
    "mesh_plot_size = domain_size*0.8\n",
    "refine_times = 6\n",
    "p = 1*kp\n",
    "source_number = 1\n",
    "source_mass = mgb/source_number\n",
    "radius_population = domain_size/2\n",
    "#Degree of the functionspace we want to solve the PDE on\n",
    "#IMPORTANT: Optimal degree = 3, increasing it to 4 does not make the computation more accurate!\n",
    "degree_PDE = 3\n",
    "#IMPORTANT!!! It might be that interpolating on a linear space makes all derivatives disappear:\n",
    "#https://fenicsproject.org/qa/9893/simple-question-about-derivation/\n",
    "#However, I should be fine cause I do the derivative, then interpolate it on a linear space and do it again\n",
    "#So I never take a second derivative on the same space technically\n",
    "#Interpolating all the lensing parameters onto new function spaces is expensive. Only do if needed\n",
    "lensing_interpolations = False\n",
    "#giving the option to use a finer, regular mesh and all functions interpolated on it for all plotting\n",
    "plotting_option = False\n",
    "#Deciding if we want the sources to all be in the same plane (can make it easier to get good contours, or\n",
    "#for thin lens approximation for lensing)\n",
    "coplanar_sources = True\n",
    "#Option to make the comparison between two solutions after the whole code has run\n",
    "make_comparison = False\n",
    "#Option to have the first mass of the distribution placed in the origin\n",
    "central_mass = True\n",
    "#Option to calculate acceleration by interpolating the gradient of the solution on a vector space. \n",
    "#The operation is very expensive, so if it's not strictly necessary it's better to not do it at all\n",
    "acceleration_needed = False\n",
    "#Option to plot 3D graphs\n",
    "plot_3D_graphs = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class for keeping track of time taken by every section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a class for runtimes of each section to profile the program. it has a time and a name\n",
    "#attribute, so when plotting we can directly use the name in e.g. a bar chart or pie chart\n",
    "class run_time:\n",
    "    \n",
    "    #initialising class\n",
    "    def __init__(self, time, name):\n",
    "        self.time = time\n",
    "        self.name = name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to define the initial mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_spherical_mesh(size, resolution):\n",
    "\n",
    "    mesh_generation_start = time.time()\n",
    "\n",
    "    print('Starting mesh generation...\\n')\n",
    "\n",
    "    #Defining the domain for the mesh using the Sphere function from mshr\n",
    "    domain = mshr.Sphere(origin, size)\n",
    "\n",
    "    #Meshing the sphere generated with resolution 10 (cells per dimension)\n",
    "    initial_mesh = mshr.generate_mesh(domain, resolution)\n",
    "\n",
    "    mesh_generation_end = time.time()\n",
    "    mesh_generation_time = run_time(mesh_generation_end - mesh_generation_start, 'Mesh Generation')\n",
    "    section_times.append(mesh_generation_time)\n",
    "    print('Mesh generated in {} s \\n'.format(mesh_generation_time.time))\n",
    "    \n",
    "    return initial_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## starting time of whole PDE solver\n",
    "starting_time = time.time()\n",
    "\n",
    "#starting an empty list to contain all of the run_time objects to plot later\n",
    "section_times = []\n",
    "\n",
    "#Making mesh from function defined above\n",
    "mesh = make_spherical_mesh(domain_size, mesh_resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining function to mark cells within a certain radius for a given mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inside_circle (mesh, radius):\n",
    "    '''Function to mark all elements that have their center farther than a certain\n",
    "    radius.'''\n",
    "    \n",
    "    #Defining the origin based on the geometric dimension of the mesh (plane 2 volume 3)\n",
    "    origin = Point(np.zeros((mesh.geometric_dimension(),1)))\n",
    "        \n",
    "    #List comprehension with a single True corresponding to the cell containing the point\n",
    "    is_in_list = [cell.distance(origin) < radius for cell in cells(mesh)]\n",
    "    \n",
    "    inside_cell_index = np.nonzero(is_in_list)\n",
    "    \n",
    "    #Converting list to a np array so it's faster (and has 0 and 1 so can be sorted)\n",
    "    is_in_numpy = np.fromiter(is_in_list, float, mesh.num_cells())\n",
    "    \n",
    "    #Indices at which we have non-zero in the numpy array are the cell indices we need\n",
    "    is_outside_index = np.nonzero(is_in_numpy)\n",
    "\n",
    "    return inside_cell_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying to create mesh from scratch using the MeshEditor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next, using the inside_circle function to exclude cells outside a given radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def circle_grid_mesh(mesh, radius, show_mesh = True):\n",
    "    \n",
    "    #Getting the MeshFunction and numpy array containing whether each cell satisfies the function\n",
    "    inside_cell_index = inside_circle(mesh, radius)\n",
    "\n",
    "    #Getting the vertex indices only for the cells that are inside the required radius\n",
    "    inside_cells_vertices_old = mesh.cells()[inside_cell_index]\n",
    "\n",
    "    #Number of remaining cells, given by the number of rows in the array (shape[0])\n",
    "    inside_cell_number = inside_cells_vertices_old.shape[0]\n",
    "\n",
    "    #Finding the indices of all the vertices included in the remaining cells (only need each index\n",
    "    #once, hence we use unique)\n",
    "    inside_vertex_old = np.unique(inside_cells_vertices_old)\n",
    "\n",
    "    #Getting the coordinates of each vertex of cells contained in the radius\n",
    "    inside_vertex_coordinates = mesh.coordinates()[inside_vertex_old]\n",
    "\n",
    "    #Number of remaining vertices (same way as for cells)\n",
    "    inside_vertex_number = inside_vertex_old.shape[0]\n",
    "\n",
    "    #New indices for the vertices, fom 0 to #vertices\n",
    "    inside_vertex_new = np.arange(inside_vertex_number)\n",
    "\n",
    "    #Replacing the old vector indices by the new vector indices in the cell array\n",
    "    #Approach from StackExchange: https://stackoverflow.com/questions/55949809/\n",
    "    #efficiently-replace-elements-in-array-based-on-dictionary-numpy-python\n",
    "    #Making np. zero array with as many elements as the initial # vertices\n",
    "    mapping_old_new = np.zeros(inside_vertex_old.max()+1,dtype=inside_vertex_new.dtype)\n",
    "\n",
    "    #Replacing the zero at the position of each old vertex, with the corresponding new vertex!\n",
    "    mapping_old_new[inside_vertex_old] = inside_vertex_new\n",
    "\n",
    "    #Now indexing each element of the mapping by an element of the cells_vertices array. So each\n",
    "    #old vertex is replaced by a new vertex! Super efficient and fast\n",
    "    inside_cells_vertices_new = mapping_old_new[inside_cells_vertices_old]\n",
    "    \n",
    "    #Now we have a list of cells and vertices that we want to put into the mesh\n",
    "    #Declaring an empty object from the MeshEditor class\n",
    "    editor = MeshEditor()\n",
    "\n",
    "    #Declaring an empty mesh to use in the mesh editor\n",
    "    test_mesh = Mesh()\n",
    "\n",
    "    #Opening the line mesh in the mesh editor, with given topological and geometric dimensions\n",
    "    editor.open(test_mesh, mesh.cell_name(), mesh.topology().dim(), mesh.geometric_dimension())\n",
    "\n",
    "    #Initialising the mesh with the # vertices corresponding to the cells inside the radius\n",
    "    editor.init_vertices(inside_vertex_number)\n",
    "\n",
    "    #Initialising an amount of cells equal to those inside the given radius\n",
    "    editor.init_cells(inside_cell_number)\n",
    "\n",
    "    #Adding all the vertices from cells inside radius\n",
    "    for vertex_index, vertex in enumerate(inside_vertex_coordinates):\n",
    "        editor.add_vertex(vertex_index, vertex)\n",
    "\n",
    "    #Giving list of cells with the new indexing\n",
    "    for cell_index, cell_vertices in enumerate(inside_cells_vertices_new):\n",
    "        editor.add_cell(cell_index, cell_vertices)\n",
    "\n",
    "    #Closing the mesh editor\n",
    "    editor.close()\n",
    "    \n",
    "    #Plotting mesh if necessary\n",
    "    if show_mesh:\n",
    "\n",
    "        plt.figure()\n",
    "        plot(test_mesh, color = 'w')\n",
    "        \n",
    "    #Returning the mesh object\n",
    "    return test_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cube_mesh(side_length, resolution):\n",
    "    \n",
    "    #Defining extremes of main diagonal to obtain side_length*3 cube\n",
    "    box_edge_low = Point(-side_length*np.array([1,1,1]))\n",
    "    box_edge_high = Point(side_length*np.array([1,1,1]))\n",
    "    \n",
    "    #Using dolfin builtin mesh, defining edges and resolution for all 3 axes\n",
    "    cubic_mesh = BoxMesh(box_edge_low, box_edge_high, resolution, resolution, resolution)\n",
    "    \n",
    "    #Object returned by BoxMesh is not a dolfin mesh, so we define it as such to be able to use it\n",
    "    cubic_mesh = Mesh(cubic_mesh)\n",
    "    \n",
    "    return cubic_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making a regular fine mesh(4 times as fine as initial unrefined mesh) to interpolate our functions over\n",
    "cubic_mesh = make_cube_mesh(2*domain_size, plot_resolution*2)\n",
    "\n",
    "#Getting a spherical mesh from the cube generated above, Making mesh slightly larger so we don't miss points \n",
    "#on the surface that are absent due to the new mesh having a smooth boundary\n",
    "mesh_for_plots = circle_grid_mesh(cubic_mesh, mesh_plot_size, show_mesh=False)\n",
    "\n",
    "#Creating a scalar function space on the large mesh, so we can interpolate functions on it and plot them\n",
    "# V_plot = FunctionSpace(mesh_for_plots, 'CG', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining coordinates for some test mass distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#For all the points to be within a given radius, each coordinate must be smaller than\n",
    "#radius_population/sqrt(3)\n",
    "random_max_distance = radius_population/sqrt(3)\n",
    "\n",
    "#Setting a given seed so we can always have the same random numbers for now\n",
    "np.random.seed(1)\n",
    "\n",
    "#We want a mean of 0 so center of mass is in center, and the same standard deviation as the gaussian\n",
    "#pulse. This means we sample from the same distribution as the smooth one, and have the same mean.\n",
    "#This is exactly what we want to compare coarse and smooth distributions\n",
    "mu, sigma = 0, stand_dev\n",
    "random_coordinates_x = np.random.normal(mu, sigma, source_number)\n",
    "random_coordinates_y = np.random.normal(mu, sigma, source_number)\n",
    "\n",
    "#If we want all source to be in the same plane, we set the z axis to be 0 for all of them. Otherwise,\n",
    "#random as above\n",
    "if coplanar_sources == True:\n",
    "    \n",
    "    random_coordinates_z = np.zeros((source_number, 1)).ravel()\n",
    "\n",
    "else:\n",
    "    \n",
    "    random_coordinates_z = np.random.normal(mu, sigma, source_number)\n",
    "\n",
    "#If we dont need Gaussian, defining a source_number*3 array of random numbers between 0 and 1 and\n",
    "#multiplying by the radius just defined so all points are inside a sphere of radius_tot.\n",
    "#Subtracting 0.5 so #we're sampling equally from the positive and negative instead of from 0 to 1\n",
    "# random_coordinates = random_max_distance * (np.random.rand(source_number, 3)-0.5)\n",
    "\n",
    "# Uncomment for test case with two equal masses on the xy plane at a given distance\n",
    "# their_distance = 3\n",
    "\n",
    "# # random_coordinates[0][0] = -domain_size/their_distance\n",
    "if central_mass:\n",
    "\n",
    "    random_coordinates_x[0] = 0\n",
    "    random_coordinates_y[0] = 0\n",
    "    random_coordinates_z[0] = 0\n",
    "\n",
    "# random_coordinates[1][0] = domain_size/their_distance\n",
    "# random_coordinates[1][1] = 0\n",
    "# random_coordinates[1][2] = 0\n",
    "\n",
    "#Overall array containing all coordinates. If over-writing the random position, this has to go after it,\n",
    "#otherwise the c++ array for the source sets the wrong position!\n",
    "random_coordinates = np.array((random_coordinates_x, random_coordinates_y, random_coordinates_z))\n",
    "random_coordinates = np.transpose(random_coordinates)\n",
    "\n",
    "#Obtaining the center of each source as a list of points\n",
    "source_centers = [Point(random_coordinates_x[i], random_coordinates_y[i], random_coordinates_z[i]) for i in range(source_number)]\n",
    "\n",
    "# Overriding definition with known point for testing of the mesh refinement\n",
    "# test_coordinates  = 5*kp*np.zeros((3,1))\n",
    "# source_centers = Point(test_coordinates)\n",
    "\n",
    "# random_coordinates\n",
    "# print(f'Mean in x: {abs(mu - np.mean(random_coordinates_x))/domain_size}\\n') \n",
    "# print(f'Mean in y: {abs(mu - np.mean(random_coordinates_y))/domain_size}\\n') \n",
    "# print(f'Mean in z: {abs(mu - np.mean(random_coordinates_z))/domain_size}\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'Random coordinates are:\\n {random_coordinates}')\n",
    "# print(source_centers[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for point in source_centers:\n",
    "    \n",
    "#     print(f'{point.x(), point.y(), point.z()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the center of mass for the mass distribution to correctly calculate BCs and initial guesses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COMMENTED OUT MOMENTARILY TO TEST HAVING SOURCE IN PLANE!\n",
    "#NEED TO TEST IF THIS WORKS CORRECTLY WITH RANDOM POINTS. PRROBLEM BEOFR EWAS WITH MESH\n",
    "#REFINEMENT, WASNT READING THE OOINT TO REFINE CORRECTLY!\n",
    "\n",
    "#For the current case in which all sources have the same mass, we simply divide by #sources\n",
    "center_of_mass_x = random_coordinates[:,0].sum()/source_number\n",
    "center_of_mass_y = random_coordinates[:,1].sum()/source_number\n",
    "center_of_mass_z = random_coordinates[:,2].sum()/source_number\n",
    "\n",
    "#Overall center of mass\n",
    "center_of_mass = [center_of_mass_x, center_of_mass_y, center_of_mass_z]\n",
    "\n",
    "# center_of_mass = test_coordinates\n",
    "# center_of_mass_x = center_of_mass[0]\n",
    "# center_of_mass_y = center_of_mass[1]\n",
    "# center_of_mass_z = center_of_mass[2]\n",
    "\n",
    "# # #Overwriting center of mass to check if the BC works correctly\n",
    "# # center_of_mass = [0,0,0]\n",
    "# source_centers[0]/kp\n",
    "\n",
    "# center_of_mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def more_modified_refinement (mesh, location, how_many):\n",
    "    '''Function to refine mesh locally, only refining cells containing one of the points described by the\n",
    "    list of Dolfin Points location,a Point for each source. \n",
    "    '''\n",
    "    \n",
    "    #Starting # cells before we refine, to compute growth factor\n",
    "    starting_cells = mesh.num_cells()\n",
    "    \n",
    "    #How_many gives the amount of time the mesh should be refined\n",
    "    if how_many > 0:\n",
    "    \n",
    "        for i in range(how_many):\n",
    "        \n",
    "            #Declaring Boolean Mesh Function to individuate cell containing point\n",
    "            contain_function = MeshFunction(\"bool\", mesh, 3)\n",
    "\n",
    "            #Setting function to False everywhere\n",
    "            contain_function.set_all(False)\n",
    "            \n",
    "            #Initial number of cells before refinement\n",
    "            initial_cells = mesh.num_cells()\n",
    "                \n",
    "            #List comprehension containing the cell IDs for the cells containing a source\n",
    "            intersect_list = [intersect(mesh, source).intersected_cells() for source in location]\n",
    "            \n",
    "            #Setting the cell function contain_function to true for each cell containing a source\n",
    "            for cell_index in intersect_list:\n",
    "                contain_function[cell_index[0]] = True\n",
    "            \n",
    "            #Refining the mesh only for cells that contain a source\n",
    "            mesh = refine(mesh, contain_function)    \n",
    "            \n",
    "            #Final # cells after refinement\n",
    "            final_cells = mesh.num_cells()\n",
    "            \n",
    "            partial_growth_factor = final_cells/initial_cells\n",
    "            \n",
    "            print(('Iteration {} of {}: The Cell number went from {} to {}, up by a factor {}\\n'\n",
    "                  .format(i+1, how_many, initial_cells, final_cells, partial_growth_factor)))\n",
    "    \n",
    "        #ratio between # cells at beginning and end of refinement\n",
    "        total_growth_factor = final_cells/starting_cells\n",
    "\n",
    "        print('Cell number went up by a factor {}\\n'.format(total_growth_factor))\n",
    "    \n",
    "    #returning the refined mesh\n",
    "    return mesh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using local mesh refinement after implementing a mesh function to mark individual cells to be refined based on some condition (page 187 of book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_refinement (mesh, location, radius, how_many, technique = 'inside'):\n",
    "    '''Function to refine mesh locally, based on the distance from a given point\n",
    "    '''\n",
    "    \n",
    "    #Starting # cells before we refine, to compute growth factor\n",
    "    starting_cells = mesh.num_cells()\n",
    "    \n",
    "    if how_many > 0:\n",
    "    \n",
    "        for i in range(how_many):\n",
    "        \n",
    "            for j, source in enumerate(location): \n",
    "                \n",
    "                print(f'Source {j+1} of {source_number}', end=\"\\r\", flush=True)\n",
    "                \n",
    "                #IMPORTANT: Need to delcare (and set to False) the cell_to_refine function\n",
    "                #for each source, as the mesh is different after each iteration!\n",
    "                #Initial mesh cell count\n",
    "                initial_cells = mesh.num_cells()\n",
    "\n",
    "                #We want to refine based on cell location, so we want to mark cells within a given radius\n",
    "                #We create a MeshFunction containing a bool for each cell (3 stands for the topological\n",
    "                #dimension, which is vertex->1, face->2, cell->3), on the given mesh\n",
    "                cell_to_refine = MeshFunction(\"bool\", mesh, 3)\n",
    "\n",
    "                #Initialising all marker to false\n",
    "                cell_to_refine.set_all(False)\n",
    "\n",
    "                #cells(mesh_trial) is an iterator, so we can loop over it directly, without needing to know\n",
    "                #anything about the cells\n",
    "                for k, cell in enumerate(cells(mesh)):\n",
    "                    \n",
    "                    if (k+1)%1000 == 0:\n",
    "                        print(f'Cells done: {int(k+1)} out of {mesh.num_cells()}', end=\"\\r\", flush=True)\n",
    "                    \n",
    "                    #With the close technique, we refine all cells with centers within a given radius\n",
    "                    if str(technique) == 'close':\n",
    "\n",
    "                        #looking at the center of the cell\n",
    "                        p = cell.midpoint()\n",
    "\n",
    "                        #if the cell is within the required radius, we set the corresponding marker to True\n",
    "                        if p.distance(source) < radius:\n",
    "\n",
    "                            cell_to_refine[cell] = True\n",
    "                        \n",
    "                    elif str(technique) == 'ring':\n",
    "\n",
    "                        #looking at the center of the cell\n",
    "                        p = cell.midpoint()\n",
    "\n",
    "                        #if the cell is within the required radius, we set the corresponding marker to True\n",
    "                        if (radius*0.9 < p.distance(source) and  (p.distance(source) < radius*1.1)):\n",
    "\n",
    "                            cell_to_refine[cell] = True    \n",
    "                    \n",
    "                    elif technique == 'inside': \n",
    "\n",
    "                        if cell.contains(source):\n",
    "\n",
    "                            cell_to_refine[cell] = True\n",
    "\n",
    "                #Refining the mesh only where the markers are True, so inside the desired radius \n",
    "                mesh = refine(mesh, cell_to_refine)\n",
    "\n",
    "                final_cells = mesh.num_cells()\n",
    "\n",
    "                partial_growth_factor = final_cells/initial_cells\n",
    "            \n",
    "            print(('Iteration {} of {}: The Cell number went from {} to {}, up by a factor {}\\n'\n",
    "                  .format(i+1, how_many, initial_cells, final_cells, partial_growth_factor)))\n",
    "    \n",
    "        #ratio between # cells at beginning and end of refinement\n",
    "        total_growth_factor = final_cells/starting_cells\n",
    "\n",
    "        print('Cell number went up by a factor {}\\n'.format(total_growth_factor))\n",
    "    \n",
    "    #returning the refined mesh\n",
    "    return mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Starting mesh refinement...\\n')\n",
    "mesh_refine_start = time.time()\n",
    "new_mesh = more_modified_refinement(mesh, source_centers, refine_times)\n",
    "# new_mesh = local_refinement(mesh, source_centers, radius_refine, refine_times, technique = 'ring')\n",
    "mesh_refine_end = time.time()\n",
    "mesh_refine_time = run_time(mesh_refine_end - mesh_refine_start, 'Mesh Refinement')\n",
    "section_times.append(mesh_refine_time)\n",
    "print('Mesh refined in {} s \\n'.format(mesh_refine_time.time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = new_mesh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gathering all the data from the mesh AFTER having done the mesh refinement and defined the mesh for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rearrange_mesh_data(mesh, C_O_M = origin, degree = 1):\n",
    "    V = FunctionSpace(mesh, 'CG', degree)\n",
    "\n",
    "    #Finding the total number of vertices in the mesh\n",
    "    vertex_number = mesh.num_vertices()\n",
    "\n",
    "    #Storing x, y, z coordinates of each point of the mesh in a separate numpy array\n",
    "    x_coords = mesh.coordinates()[:,0]\n",
    "    y_coords = mesh.coordinates()[:,1]\n",
    "    z_coords = mesh.coordinates()[:,2]\n",
    "\n",
    "    #using the numpy linalg.norm function to get the radius(norm) of each vertex\n",
    "    r_coords = np.linalg.norm(mesh.coordinates(), axis=1)\n",
    "    \n",
    "    r_coords_CM = (np.sqrt(np.square(x_coords-C_O_M [0]) +\n",
    "    np.square(y_coords-C_O_M [1]) + np.square(z_coords-C_O_M [2])))\n",
    "    \n",
    "    #Storing the index to sort according to r\n",
    "    sorting_index = r_coords_CM.argsort()\n",
    "\n",
    "    #Sorted radial distances\n",
    "    r_sorted = r_coords_CM[sorting_index]\n",
    "\n",
    "    #Sorted coordinates\n",
    "    x_sorted = x_coords[sorting_index]\n",
    "    y_sorted = y_coords[sorting_index]\n",
    "    z_sorted = z_coords[sorting_index]\n",
    "\n",
    "    return V, vertex_number, x_coords, y_coords, z_coords, r_coords, sorting_index, x_sorted, y_sorted, z_sorted, r_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Rearranging mesh data\\n')\n",
    "rearrange_start = time.time()\n",
    "\n",
    "#IMPORTANT: Tried solving the whole PDE with degree 2, so that taking the Laplacian of the solution would\n",
    "#give a smoother expression. However, that did not work for mesh resolution = 21 ,it takes up too much\n",
    "#memory and cant be run. Can solve up to degree 3 but with low resolution = 11. Can't do degree = 4!\n",
    "#The alternative is to take the solution itself and take its Laplacian and project it on a degree 3 space\n",
    "#Calling the rearrange_mesh_data function to get coordinates and order them based on the \n",
    "#distance from the center of mass\n",
    "V, vertex_number, x_coords, y_coords, z_coords, r_coords, sorting_index, x_sorted, y_sorted, z_sorted, r_sorted = rearrange_mesh_data(mesh, center_of_mass, degree_PDE)\n",
    "\n",
    "rearrange_end = time.time()\n",
    "rearrange_time = run_time(rearrange_end - rearrange_start, 'Mesh data rearrange')\n",
    "section_times.append(rearrange_time)\n",
    "print('Mesh data rearranged in {} s \\n'.format(rearrange_time.time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to make string for discrete delta peak distribution of source_number #masses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discrete_dirac(how_many_sources):\n",
    "    '''Function to generate a c++ string giving a discrete distribution of delta peaks (modelled as\n",
    "    spheres of uniform mass with a very small radius) at arbitrary points. The number of sources is\n",
    "    given by how_many_sources. The positions have to be specified explicitly, one by one, which is\n",
    "    achieved by the make_source_string function'''\n",
    "\n",
    "    #Starting the string with an open bracket so we can have the whole conditional statement between\n",
    "    #brackets\n",
    "    discrete_string = '('\n",
    "\n",
    "    #Looping over the nummber of sources to generate a conditional statement for each\n",
    "    for i in range(how_many_sources):\n",
    "\n",
    "        #For all loop iterations apart from the last one, we add the condition for a sphere\n",
    "        #at the respective location, and add an OR(||) at the end to chain it to the next\n",
    "        if i != how_many_sources - 1:\n",
    "\n",
    "            discrete_string = discrete_string + ('((pow((x[0]-position_x_{}),2)+pow((x[1]-position_y_{}),2)'\n",
    "            '+pow((x[2]-position_z_{}),2)) <=pow(radius_tot, 2)) ||'.format(i,i,i))\n",
    "\n",
    "        #If it's the last iteration, we don't add an OR but a conditional delimiter (?), and add the\n",
    "        #body of the loop containing if/not the condition is satisfied\n",
    "        else:\n",
    "\n",
    "            discrete_string = discrete_string + ('((pow((x[0]-position_x_{}),2)+pow((x[1]-position_y_{}),2)'\n",
    "            '+pow((x[2]-position_z_{}),2)) <=pow(radius_tot, 2)))? '.format(i,i,i))\n",
    "\n",
    "            discrete_string = discrete_string + '4*pi*G*source_mass/volume_out : 0'\n",
    "        \n",
    "    return discrete_string\n",
    "    \n",
    "#     print('The string for the {}th iteration is:\\n {}\\n'.format(i, string_cpp))\n",
    "    \n",
    "# string_cpp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to make a discrete distribution, but using Gaussians instead of delta peaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discrete_gauss(how_many_sources):\n",
    "    '''Function to generate a c++ string giving a discrete distribution of delta peaks (modelled as\n",
    "    spheres of uniform mass with a very small radius) at arbitrary points. The number of sources is\n",
    "    given by how_many_sources. The positions have to be specified explicitly, one by one, which is\n",
    "    achieved by the make_source_string function'''\n",
    "\n",
    "    #Starting the string with an open bracket so we can have the whole conditional statement between\n",
    "    #brackets\n",
    "    discrete_string = ('(4*pi*G*pow(2*pi,-1.5)*source_mass/pow(stand_dev_peak,3)*(')\n",
    "\n",
    "    #Looping over the nummber of sources to generate a conditional statement for each\n",
    "    for i in range(how_many_sources):\n",
    "\n",
    "        #For all loop iterations apart from the last one, we add the condition for a sphere\n",
    "        #at the respective location, and add an OR(||) at the end to chain it to the next\n",
    "        if i != how_many_sources - 1:\n",
    "\n",
    "            discrete_string = discrete_string + ('exp(-(pow((x[0]-position_x_{}),2) +'\n",
    "            ' pow((x[1]-position_y_{}),2) +'\n",
    "            ' pow((x[2]-position_z_{}),2))/(2*(pow(stand_dev_peak,2))))+'.format(i,i,i))\n",
    "\n",
    "        #If it's the last iteration, we don't add an OR but a conditional delimiter (?), and add the\n",
    "        #body of the loop containing if/not the condition is satisfied\n",
    "        else:\n",
    "\n",
    "            discrete_string = discrete_string + ('exp(-(pow((x[0]-position_x_{}),2) +'\n",
    "            ' pow((x[1]-position_y_{}),2) +'\n",
    "            ' pow((x[2]-position_z_{}),2))/(2*(pow(stand_dev_peak,2))))))'.format(i,i,i))\n",
    "        \n",
    "    return discrete_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C++ Expressions for the sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VERY IMPORTANT: Each constant used in declaring an expression in c++ code needs to be\n",
    "#declared inside Expression, after the degree! If not, the c++ compiler will throw an error!\n",
    "#IMPORTANT!: Cannot use the log function cause that name is apparently already taken by some\n",
    "#other function, not the logarithm! So using log10 and rescaling by 0.43429.\n",
    "#IMPORTANT!! When changing the radius_tot in the above script is doesn't change in here cause\n",
    "#it has to be defined independently for all of these C++ expressions! If you don't change it \n",
    "#inside here for both u and f, the solution will be wrong!\n",
    "\n",
    "#Sphere of constant density\n",
    "#Using separate '...' on each line so I can write the C++ code over multiple lines, less messy\n",
    "f_sphere_cpp = ('(pow(x[0],2) + pow(x[1],2) + pow(x[2],2))<=pow(radius_tot, 2) ?'\n",
    "'4*pi*G*mgb/volume_out : 0')\n",
    "\n",
    "# Dirac Delta function using conditional for each coordinate (doesnt work)\n",
    "f_dirac_coord_cond_cpp = ('(abs(x[0]-x_close) <= x_close && '\n",
    "                                   'abs(x[1]-y_close) <= y_close && '\n",
    "                                   'abs(x[2]-z_close) <= z_close)  ? '\n",
    "                                   '4*pi*G*mgb: 0')\n",
    "\n",
    "#Dirac delta using very small radius (doesnt work)\n",
    "f_dirac_radius_cond_cpp = ('pow(x[0],2) + pow(x[1],2) + pow(x[2],2) <= 2*pow(radius_close,2)'\n",
    "                           ' ? mgb : 0')\n",
    "\n",
    "#Dirac Delta using definition (as suggested here https://fenicsproject.org/qa/7941/applying-\n",
    "#dirac-function-using-fenics-pointsource-function/)\n",
    "f_dirac_analytic1_cpp = ('4*pi*G*mgb*eps/pi*1/(pow(x[0],2) + pow(x[1],2) + pow(x[2],2) + pow(eps,2))')\n",
    "\n",
    "#Defining a Gaussian pulse with a standard deviation radiustot/3, so 99.7% of mass is inside\n",
    "#radius tot and we can compare with the analytic solution for a sphere\n",
    "f_gauss_cpp = ('4*pi*G*mgb*(1/pow((stand_dev*sqrt(2*pi)),3))*exp(-(1/2)*((pow(x[0]-x_close ,2)'\n",
    "               '+ pow(x[1] - y_close,2) + pow(x[2] - z_close,2))/(pow(stand_dev,2))))')\n",
    "\n",
    "#Defining the source and initial guess for an isothermal distribution\n",
    "f_isothermal_cpp = ('4*pi*G*3*mgb/(4*pi)*pow((pow(p, 1/2)/(pow(p, 3/2) +'\n",
    "                    'pow((pow(x[0],2) + pow(x[1],2) + pow(x[2],2)), 3/4))), 3)')\n",
    "\n",
    "#Testing the exponential function in the source cause it doesnt seem to work, THIS WORKS!\n",
    "#APART FROM HAVING SLIGHTLY MORE MASS THAN IT SHOULD!\n",
    "f_exponent_test = ('4*pi*G*pow(2*pi,-1.5)*source_mass/pow(stand_dev,3)*exp(-(pow(x[0],2) + pow(x[1],2) + pow(x[2],2))/(2*(pow(stand_dev,2))))')\n",
    "\n",
    "#Trying to implement a for loop inside the Expression statement\n",
    "f_displaced_cpp = ('(pow((x[0]-position_x),2)+pow((x[1]-position_y),2)+pow((x[2]-position_z),2))'\n",
    "                '<=pow(radius_tot, 2) ?'\n",
    "                '4*pi*G*source_mass/volume_out : 0')\n",
    "\n",
    "#Calling the function to make the cpp code for the discrete distribution and assigning the output\n",
    "#to the string_cpp variable\n",
    "f_multiple_dirac = make_discrete_dirac(source_number)\n",
    "\n",
    "#Source expression for multiple sources using a for loop over the source locations defining\n",
    "#the string itself, as in the cell above\n",
    "f_multiple_gauss = make_discrete_gauss(source_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C++ Expressions for the Initial Guesses/BCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solution for a sphere of uniform density, including the solution inside and outside the sphere\n",
    "u_sphere_cpp = ('(pow(x[0],2) + pow(x[1],2) + pow(x[2],2))>=pow(radius_tot, 2) ?'\n",
    "'sqrt(G*mgb*a0)*1/2*2.3026*log10(pow(x[0],2)+pow(x[1],2)+pow(x[2],2)) :'\n",
    "'(4/3*sqrt(pi/3*a0*G*mgb/volume_out)*3/2*pow((pow(x[0],2)+pow(x[1],2)+pow(x[2],2)),3/4)+'\n",
    "'sqrt(G*mgb*a0)*2.3026*log10(radius_tot)-4/3*sqrt(pi/3*a0*G*mgb/volume_out)*'\n",
    "'3/2*pow(radius_tot,3/2))')\n",
    "\n",
    "#Dirac delta in the origin\n",
    "u_dirac_cpp = ('sqrt(G*mgb*a0)*1/2*2.3026*log10(pow(x[0],2)+pow(x[1],2)+pow(x[2],2))')\n",
    "\n",
    "#Solution for a mass distribution follwoing an isothermal profile\n",
    "u_isothermal_cpp = ('2/3*sqrt(G*mgb*a0/6)*2.3206*log10(1 + pow((pow(x[0],2) + '\n",
    "                    'pow(x[1],2) + pow(x[2],2)), 3/4) / pow(p, 3/2))')\n",
    "\n",
    "#Boundary condition for displaced source/center of mass\n",
    "u_displaced_cpp = ('sqrt(G*source_mass*a0)*1/2*2.3026*log10(pow((x[0] - center_of_mass_x),2)'\n",
    "                          '+pow((x[1] - center_of_mass_y),2)+pow((x[2] - center_of_mass_z),2))')\n",
    "\n",
    "#Boundary condition for Newtonian Gravity\n",
    "u_Newton = ('-G*mgb/sqrt(pow((x[0] - center_of_mass_x),2)'\n",
    "                          '+pow((x[1] - center_of_mass_y),2)+pow((x[2] - center_of_mass_z),2))')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C++ Expressions for the weak form of a specific PDE, e.g. different interpolation of GEA modification. Defined as strings to be evaluated with eval cause Python doesnt know what u is yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Weak for for Newton\n",
    "F_Newton = 'inner(grad(u), grad(v))*dx + f*v*dx'\n",
    "\n",
    "#Weak form for deep MOND\n",
    "F_MOND_deep = 'inner(sqrt(inner(grad(u), grad(u))) * grad(u)/a0, grad(v))*dx + f*v*dx'\n",
    "\n",
    "#Weak form for the simple interpolation function\n",
    "F_MOND_simple = ('inner(sqrt(inner(grad(u), grad(u)))/(sqrt(inner(grad(u), grad(u)))+a0)'\n",
    "              '* grad(u), grad(v))*dx + f*v*dx')\n",
    "    \n",
    "#Weak form for the standard interpolation function\n",
    "F_MOND_standard = ('inner(sqrt(inner(grad(u), grad(u)))/sqrt((inner(grad(u), grad(u))+a0**2))'\n",
    "              '* grad(u), grad(v))*dx + f*v*dx')\n",
    "\n",
    "#Weak form for the exponential interpolation function. Doesnt seem to work but it behaves almost exactly\n",
    "#the same as the standard inteprolation function, so it's not so bad.\n",
    "F_MOND_exponential  = ('inner(1-exp(-sqrt((inner(grad(u), grad(u))))/a0)'\n",
    "              '* grad(u), grad(v))*dx + f*v*dx')\n",
    "\n",
    "# #Defining the r unit vector in terms of cartesian coordinates for use in weak form of GEA\n",
    "r_unit_1 = Expression('x[0]/sqrt(x[0]*x[0]+x[1]*x[1]+x[2]*x[2])', degree = 1)\n",
    "r_unit_2 = Expression('x[1]/sqrt(x[0]*x[0]+x[1]*x[1]+x[2]*x[2])', degree = 1)\n",
    "r_unit_3 = Expression('x[2]/sqrt(x[0]*x[0]+x[1]*x[1]+x[2]*x[2])', degree = 1)\n",
    "\n",
    "#Weak form for GEA with spherical symmetry component. Multiplying the distribution by 6/beta as for GEA\n",
    "#we use the acceleration scale M=6a_0, so a_0-> 6a_0 and we need to divide by beta\n",
    "F_MOND_GEA = ('(inner(sqrt(2*inner(grad(u_GEA), grad(u_GEA)) - c_2*((u_GEA.dx(0)*r_unit_1)+'\n",
    "        '(u_GEA.dx(1)*r_unit_2)+(u_GEA.dx(2)*r_unit_3))**2)* grad(u_GEA), grad(v))*dx + 6/beta*f*v*dx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_string = make_discrete_gauss(10)\n",
    "# print(f'The generated string is:\\n {test_string},\\n The normal string is:\\n {f_exponent_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making a class for a Boundary Value Problem. This way we can define a BVP by specifying its weak form (LHS of the PDE), initial guess (also the BC), source (RHS of PDE) and name (for plotting etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a class for runtimes of each section to profile the program. it has a time and a name\n",
    "#attribute, so when plotting we can directly use the name in e.g. a bar chart or pie chart\n",
    "class BVP:\n",
    "    \n",
    "    #initialising class\n",
    "    def __init__(self, weak_form, initial_guess, source, name):\n",
    "        self.weak_form = weak_form\n",
    "        self.initial_guess = initial_guess\n",
    "        self.source = source\n",
    "        self.name = name\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining a few BVP from combinations we use often. Naming scheme: 'weak form_source'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BVPs for a discrete dirac mass distribution, for Newton and MOND with/out interpolations\n",
    "newton_dirac = BVP(F_Newton, u_Newton, f_multiple_dirac, 'Newton, discrete dirac')\n",
    "mond_deep_dirac = BVP(F_MOND_deep, u_displaced_cpp, f_multiple_dirac, 'Deep MOND, discrete dirac')\n",
    "mond_simple_dirac = BVP(F_MOND_simple, u_displaced_cpp, f_multiple_dirac, 'Simple MOND, discrete dirac')\n",
    "mond_standard_dirac = BVP(F_MOND_standard, u_displaced_cpp, f_multiple_dirac, 'Standard MOND, discrete dirac')\n",
    "\n",
    "#BVPs for a discrete gauss mass distribution.\n",
    "newton_gauss = BVP(F_Newton, u_Newton, f_multiple_gauss, 'Newton, discrete gauss')\n",
    "mond_deep_gauss = BVP(F_MOND_deep, u_displaced_cpp, f_multiple_gauss, 'Deep MOND, discrete gauss')\n",
    "mond_simple_gauss = BVP(F_MOND_simple, u_displaced_cpp, f_multiple_gauss, 'Simple MOND, discrete gauss')\n",
    "mond_standard_gauss = BVP(F_MOND_standard, u_displaced_cpp, f_multiple_gauss, 'Standard MOND, discrete gauss')\n",
    "\n",
    "#BVPs for a continuous distribution, for Newton and MOND with/out interpolations\n",
    "newton_continuous = BVP(F_Newton, u_Newton, f_exponent_test, 'Newton, continuous gauss')\n",
    "mond_deep_continuous = BVP(F_MOND_deep, u_displaced_cpp, f_exponent_test, 'Deep MOND, continuous gauss')\n",
    "mond_simple_continuous = BVP(F_MOND_simple, u_displaced_cpp, f_exponent_test, 'Simple MOND, continuous gauss')\n",
    "mond_standard_continuous = BVP(F_MOND_standard, u_displaced_cpp, f_exponent_test, 'Standard MOND, continuous gauss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to take a c++ string defining multiple discrete masses and defining all quantities inside the Expression, and all source positions one by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_source_string(how_many_sources):\n",
    "    '''Function to take an initial c++ expression, add all the required constants, and then adding\n",
    "    all the coordinates for each source we want to add from the random_coordinates arrays'''\n",
    "    \n",
    "    #Defining the initial string that we want to add the variable source location definitions to\n",
    "    executable_string = ('(Expression(source,'\n",
    "    'degree = degree_PDE, a0 = a0, ms = ms,mgb = mgb, G = G,  ly = ly, kp = kp, radius_tot = radius_tot,'\n",
    "    'volume_out = volume_out, stand_dev = stand_dev, stand_dev_peak=stand_dev_peak, p=p,'\n",
    "    'source_number = source_number, source_mass = source_mass')\n",
    "\n",
    "    #Looping over each source and generating a string assigning the value of the source position\n",
    "    #in x,y,z, directions to the corresponding variable\n",
    "    for i in range(how_many_sources):\n",
    "\n",
    "        executable_string = (executable_string + ',position_x_{} = random_coordinates_x[{}],'\n",
    "        'position_y_{} = random_coordinates_y[{}], position_z_{} = random_coordinates_z[{}]'\n",
    "        .format(i,i,i,i,i,i))\n",
    "\n",
    "    #Adding two closing brackets to close the expression\n",
    "    executable_string = executable_string+'))'\n",
    "    \n",
    "#     executable_string = eval(executable_string)\n",
    "    \n",
    "    return executable_string\n",
    "\n",
    "#Printing the final string to check if it's correct\n",
    "# print('Final string is:\\n{}\\n'.format(f_string_to_execute))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying an alternative method for assigning values inside the c++ expressions by using exec, to avoid the limit on eval!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test_string = make_source_string(10)\n",
    "# test_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining a function for the boundary. Since we only have one BC for the whole boundary, we\n",
    "#can make a simple function that returns true for each value on the boundary\n",
    "#the on_boundary built-in function takes each point in domain and returns true if on boundary\n",
    "def boundary(x, on_boundary):\n",
    "    return on_boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to Solve the PDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def solve_PDE(the_BVP):\n",
    "    '''Function takes in a BVP object, which defines the weak form, initial guess/BC and source for\n",
    "    a PDE, and computes its solution'''\n",
    "    \n",
    "    ## starting time of PDE solver\n",
    "    solver_start = time.time()\n",
    "    print('Starting PDE Solver...\\n')\n",
    "\n",
    "    #defining the x,y,z coordinates from the coordinate array in sympy\n",
    "#     x, y, z = sym.symbols('x[0], x[1], x[2]')\n",
    "\n",
    "    #VERY IMPORTANT: If using sympy, use sym. in front of every mathematical operator, or the sym. and UFL (the\n",
    "    #mathematical syntax used in fenics) collide and an error about UFL conversion appears\n",
    "    \n",
    "    #Defining the source term here, cause the make_source_string function creates a string that \n",
    "    #evaluate the expression for a variable called 'source'\n",
    "    source = the_BVP.source\n",
    "    \n",
    "    #Evaluating the source term obtained from the make_source_string function\n",
    "    f = eval(make_source_string(source_number))\n",
    "    \n",
    "    #Declaring the expression for the initial guess\n",
    "    u = (Expression(the_BVP.initial_guess,\n",
    "    degree = degree_PDE, a0 = a0, ms = ms,mgb = mgb, G = G,  ly = ly, kp = kp, radius_tot = radius_tot,\n",
    "    volume_out = volume_out, center_of_mass_x = center_of_mass_x,\n",
    "    center_of_mass_y = center_of_mass_y, center_of_mass_z = center_of_mass_z,\n",
    "    source_number = source_number, source_mass = source_mass))\n",
    "\n",
    "    #Declaring the expression for the boundary condition with displaced CM (center of mass)\n",
    "    boundary_CM = u\n",
    "\n",
    "    #Declaring the boundary condition. It takes three arguments: function space, value of BC, \n",
    "    #section of the boundary (in our case the whole boundary).\n",
    "    bc = DirichletBC(V, boundary_CM, boundary)\n",
    "\n",
    "    #Defining the variational problem\n",
    "    #u is the solution. for linear problems, we'd have to define it as TrialFunction, but for \n",
    "    #non-linear we define it as Function directly\n",
    "    u = interpolate(u, V)\n",
    "\n",
    "    #defining the test function\n",
    "    v = TestFunction(V)\n",
    "\n",
    "    #defining the weak form to be solved\n",
    "    F = eval(the_BVP.weak_form)\n",
    "\n",
    "    #Computing the solution for normal deep MOND\n",
    "    (solve(F == 0, u, bc, solver_parameters={\"newton_solver\":{\"relative_tolerance\":1e-6},\n",
    "                                             \"newton_solver\":{\"maximum_iterations\":200}}))\n",
    "\n",
    "    solver_end = time.time()\n",
    "    solver_time = run_time(solver_end - solver_start, 'PDE Solver')\n",
    "    section_times.append(solver_time)\n",
    "\n",
    "    print('PDE solved in {}\\n'.format(solver_time.time))\n",
    "    \n",
    "    return u, f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u, f = solve_PDE(mond_deep_dirac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# form_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots\n",
    "## First, the potential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a function to set x,y,z axes labels and ticks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_format(plot_to_format, dimension, radial, scale = 6):\n",
    "    '''Format the 1D, 2D and 3D plots. Takes as input the dimension of the graph (1D,2D,3D),\n",
    "    whether the plot is radial in 1D to set the x axis limits, and the scale of the system,\n",
    "    indicating the power of parsec: 6 is Mpc, 3 is Kpc and so on.'''\n",
    "    \n",
    "    #Setting a different unit depending on the scale, to be added to the corresponding axis\n",
    "    if scale == 6:\n",
    "        dim = ' (Mpc)'\n",
    "    else:\n",
    "        dim = ' (kpc)'\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    #The grid can be given for a subplot, all the other things must be given as the plot itself\n",
    "    #So the input to the function can actually be a subplot now\n",
    "    plot_to_format.grid()\n",
    "    #*args gives an arbitrary # of inputs. we take the 1st one to define if the plot is radial\n",
    "    #if it is (=1), we only need to plot from 0, not -domainsize\n",
    "    if radial == 0:\n",
    "        plt.xlabel('x'+ dim)\n",
    "        (plt.xticks(np.linspace(-domain_size,domain_size,11), 1/(10**(scale-3)*kp)\n",
    "                    *np.linspace(-domain_size,domain_size,11)))\n",
    "    else:\n",
    "        plt.xlabel('r'+ dim)\n",
    "        plt.xticks(np.linspace(0,domain_size,11), 1/(10**(scale-3)*kp)*np.linspace(0,domain_size,11))\n",
    "    if dimension == 2:\n",
    "        plt.ylabel('y'+ dim)\n",
    "        plt.yticks(np.linspace(-domain_size,domain_size,11),1/(10**(scale-3)*kp)\n",
    "                    *np.linspace(-domain_size,domain_size,11))\n",
    "    elif dimension == 3:\n",
    "#         plt.zlabel('z'+ dim)\n",
    "        plt.zticks(np.linspace(0,domain_size,11),1/(10**(scale-3)*kp)\n",
    "                    *np.linspace(-domain_size,domain_size,11))\n",
    "    else:\n",
    "        None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a function to add useful annotations to radial graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_annotations(plot_to_annotate):\n",
    "    #Adding a vertical line to denote the end of the mass distribution\n",
    "    plt.axvline(x = radius_tot, color = 'k', linestyle = '-.', linewidth = 1, label = 'Mass Density')\n",
    "\n",
    "    #and another to signal where the transition between Newton and MOND occurs\n",
    "    plt.axvline(x = sqrt(G*mgb/a0), color ='k',linestyle ='--',linewidth = 1,label = 'Transition')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the values of the function, its gradient and the source at each vertex of the mesh, and the coordinates at each point of the mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collection_start = time.time()\n",
    "print('Collecting data from PDE...\\n')\n",
    "\n",
    "if plotting_option == True:\n",
    "    mesh = mesh_for_plots\n",
    "    V_plot, vertex_number, x_coords, y_coords, z_coords, r_coords, sorting_index, x_sorted, y_sorted, z_sorted, r_sorted = rearrange_mesh_data(mesh, center_of_mass)\n",
    "    u_plot = interpolate(u, V_plot)\n",
    "    f_plot = interpolate(f, V_plot)\n",
    "    u = u_plot\n",
    "    #Calling the rearrange_mesh_data function to get coordinates and order them based on the \n",
    "    #distance from the center of mass\n",
    "\n",
    "#These options that are commented out were an attempt to solve the PDE on a lower degree, then \n",
    "#project it on a higher degree space. Doesnt work very well as you cant project a degree 1 on a degree 2\n",
    "#properly. It's essentially asking a quadratic form from a linear form for each element\n",
    "# #setting the degree for the function space onto which we want to project the solution \n",
    "# higher_degree = 3\n",
    "\n",
    "# #Function space for higher_degree\n",
    "# V_higher_degree = FunctionSpace(mesh, 'CG', higher_degree)\n",
    "\n",
    "# #Solution projected over the higher degree function space\n",
    "# u_higher_degree = project(u, V_higher_degree)\n",
    "\n",
    "# #Assigning the higher degree solution to u and doing all calculations with this\n",
    "# u = u_higher_degree\n",
    "\n",
    "\n",
    "#The value of the function at each vertex of the mesh is stored in a np array. Its order\n",
    "#corresponds to the otder of the mesh.coordinates() values\n",
    "potential = u.compute_vertex_values()\n",
    "\n",
    "#The value of the source at each vertex of the mesh\n",
    "source = f.compute_vertex_values(mesh)\n",
    "\n",
    "#Getting the degree from the scalar function space V from the PDE\n",
    "degree = V.ufl_element().degree()\n",
    "\n",
    "# #Setting the degree for all projections equal to the degree we use for the projection of the solution\n",
    "# #above\n",
    "# degree = higher_degree\n",
    "\n",
    "\n",
    "#\n",
    "lap = div(grad(u))\n",
    "\n",
    "apparent_mass_project = project(lap, V)\n",
    "\n",
    "if lensing_interpolations:\n",
    "\n",
    "    #For integration, we can only act on (scalar) FunctionSpace. Hence, we project each derivative\n",
    "    #of u individually onto the same function space as u\n",
    "    #If having problem with space, check the page that suggested this\n",
    "    #https://fenicsproject.org/qa/3688/derivative-in-one-direction/\n",
    "    acceleration_project_vector = [project(u.dx(i), V) for i in range(3)]\n",
    "\n",
    "    #Declaring a tensor(matrix) function space onto which to project the Jacobian of the potential\n",
    "    T = TensorFunctionSpace(mesh, 'P', degree)\n",
    "\n",
    "    #Projecting the gradient of the gradient (jacobian) of the potential onto TensorFunctionSpace\n",
    "    lensing_jacobian_project = project(grad(acceleration_project), T)\n",
    "\n",
    "    #First, getting each element of the lensing jacobian into a 1*9 list by differentiating each\n",
    "    #element of the acceleration list w.r.t. each coordinate. List is handy to loop over\n",
    "    #with only one index, e.g. to integrate or graph\n",
    "    lensing_jacobian_project_list = ([project(acceleration_project_vector[i].dx(j), V) \n",
    "                                        for i in range(3) for j in range(3)])\n",
    "\n",
    "    #Next, reshaping the list into a 3x3 array so we can access it by pair of coordinates\n",
    "    lensing_jacobian_project_matrix = np.reshape(lensing_jacobian_project_list,(3,3))\n",
    "\n",
    "    #Putting the values of the Jacobian into a np array\n",
    "    lensing_jacobian_magnitude = lensing_jacobian_project.compute_vertex_values()\n",
    "\n",
    "    #Reshaping the lensing jacobian into a matrix of vectors, an order 3 tensor, to have the value\n",
    "    #the jacobian at each point in space, like with the acceleration\n",
    "    lensing_jacobian_magnitude = (np.reshape(lensing_jacobian_magnitude, (3, 3,\n",
    "                                             int(lensing_jacobian_magnitude.shape[0]/9))))    \n",
    "\n",
    "#Projecting the acceleration onto a vector space is expensive, so don't do it unless needed\n",
    "#If not needed, set acceleration to 0 everywhere\n",
    "if acceleration_needed:\n",
    "    \n",
    "    #To obtain the values for the acceleration, we need to define a new function space, since the \n",
    "    #gradient is a vector function is the function space for the PDE is a scalar function space\n",
    "    W = VectorFunctionSpace(mesh, 'P', degree)\n",
    "    \n",
    "    #Projecting (similar to interpolating) the grad(u) field onto W, gives a function\n",
    "    acceleration_project = project(grad(u), W)\n",
    "\n",
    "    #The result of project is n*3,1 np.array, with 3 (x,y,z) values for each of the n vertices\n",
    "    acceleration = acceleration_project.compute_vertex_values()\n",
    "    \n",
    "    #reshaping the array to split the x,y,z components into their own column each\n",
    "    acceleration = np.reshape(acceleration, (3, int(acceleration.shape[0]/3)))\n",
    "    \n",
    "else:\n",
    "    \n",
    "    acceleration = np.zeros((3, len(potential)))\n",
    "    \n",
    "\n",
    "acceleration_x = acceleration[0]\n",
    "acceleration_y = acceleration[1]\n",
    "acceleration_z = acceleration[2]\n",
    "\n",
    "#Finding the magnitude of the acceleration\n",
    "acceleration_magnitude = np.linalg.norm(acceleration, axis=0)\n",
    "\n",
    "#Sorting the potential, acceleration and source according to thr r of the vertex they pertain to\n",
    "potential_sorted = potential[sorting_index]\n",
    "acceleration_magnitude_sorted = acceleration_magnitude[sorting_index]\n",
    "source_sorted = source[sorting_index]\n",
    "\n",
    "data_collection_end = time.time()\n",
    "data_collection_time = run_time(data_collection_end - data_collection_start, 'Data Collection')\n",
    "section_times.append(data_collection_time)\n",
    "print('Data collected in {} s\\n'.format(data_collection_time.time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating the Laplacian of the potential to obtain the apparent dark matter distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The apparent mass distribution is the RHS of the Newtonian Poisson equation. No need to scale it as it\n",
    "#is already scaled in the expression for the source itself\n",
    "# apparent_mass_divergence = div(acceleration_project)\n",
    "\n",
    "# #Projecting the divergence above onto the same scalar function space as the potential\n",
    "# apparent_mass_project = project(apparent_mass_divergence, V)\n",
    "\n",
    "#Gathering the values of the mass distribution \n",
    "apparent_mass_distribution = apparent_mass_project.compute_vertex_values()\n",
    "\n",
    "#Sorting the mass distribution values\n",
    "apparent_mass_distribution_sorted = apparent_mass_distribution[sorting_index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining function to integrate over line in the domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_integral(integrand, A, B, n, show = False): \n",
    "    '''Integrate u over segment [A, B] partitioned into n elements'''\n",
    "    \n",
    "    #This code comes from the Fenics Forum. Changed it to suit what I need to do. Link:\n",
    "    #https://fenicsproject.org/qa/13863/integrate-along-axes-lines/\n",
    "    #Assert statements are used to check expressions are of the correct form. If the assert \n",
    "    #statement would return False, then the program throws an error\n",
    "    #value_rank has to be 0 because we can only integrate over scalar Function Spaces!\n",
    "    assert u.value_rank() == 0\n",
    "    assert len(A) == len(B) > 1 and np.linalg.norm(A-B) > 0\n",
    "    assert n > 0\n",
    "    \n",
    "    #Defining an np array starting at A, getting to B in n steps\n",
    "    mesh_points = [A + t*(B-A) for t in np.linspace(0, 1, n+1)]\n",
    "    \n",
    "    #Uncomment to check the mesh points are the correct ones\n",
    "#     print(f'The mesh points are {mesh_points}\\n')\n",
    "    \n",
    "    #the topological and geometric dimensions of the points(topological is always one for a\n",
    "    #point), geometric depends on the #coordinates, here will be 3 as we're in 3D\n",
    "    tdim, gdim = 1, len(A)\n",
    "    \n",
    "    #Declaring an empty mesh\n",
    "    line_mesh = Mesh()\n",
    "    \n",
    "    #Declaring an empty object from the MeshEditor class\n",
    "    editor = MeshEditor()\n",
    "    \n",
    "    #Opening the line mesh in the mesh editor, with given topological and geometric dimensions\n",
    "    #Had too add 'interval' for the degree, as it is required in the newest version\n",
    "    editor.open(line_mesh, 'interval', tdim, gdim)\n",
    "    \n",
    "    #Initialising the line mesh with the #vertices declared in the function definition\n",
    "    editor.init_vertices(n+1)\n",
    "    \n",
    "    #Initialising n cells (1 less than the vertices, one cell for every two adjacent vertices)\n",
    "    editor.init_cells(n)\n",
    "    \n",
    "    #Adding the declared vertices to the MeshEditor\n",
    "    for vi, v in enumerate(mesh_points): editor.add_vertex(vi, v)\n",
    "    \n",
    "    #Declaring each cell to be made of the two current adjacent vertices\n",
    "    for ci in range(n): editor.add_cell(ci, np.array([ci, ci+1], dtype='uintp'))\n",
    "    \n",
    "    #Closing the mesh editor\n",
    "    editor.close()\n",
    "\n",
    "    #Setting up the function space from the function we want to plot\n",
    "    elm = integrand.function_space().ufl_element()\n",
    "    \n",
    "    #Finding family and degree properties of the potential ('P' and 1 usually)\n",
    "    family = elm.family()\n",
    "    degree = elm.degree()\n",
    "    \n",
    "    #Defining a function space for the function on the 1-D line mesh defined above\n",
    "    V = FunctionSpace(line_mesh, family, degree)\n",
    "    \n",
    "    #Interpolating the potential over the function space for the 1-D line mesh\n",
    "    v = interpolate(integrand, V)\n",
    "    \n",
    "    #Performing the integration on the defined line mesh\n",
    "    integral = assemble(v*dx)\n",
    "    \n",
    "    #Set show = True to check the line is being plotted correctly\n",
    "    \n",
    "    if show:\n",
    "        \n",
    "        #Adding figure \n",
    "        figure = plt.figure()\n",
    "        \n",
    "        #projection='3d' needed to specify a 3D scatter plot\n",
    "        integral_scatter = figure.add_subplot(111, projection='3d')\n",
    "        \n",
    "        #Plotting the mesh\n",
    "        plot(mesh, alpha = 0.5, color = 'w')\n",
    "        \n",
    "        #Scattering the line_mesh points as blue crosses\n",
    "        integral_scatter.scatter(mesh_points, 0, 0, marker = '+', color = 'b', s = 0.5)\n",
    "        \n",
    "        #Scattering the sources\n",
    "        integral_scatter.scatter(random_coordinates[:,0],random_coordinates[:,1], \n",
    "        random_coordinates[:,2], marker = 'o', color = 'r', s=1)\n",
    "    \n",
    "    #Returning the integral of the interpolated potential over the line mesh declared\n",
    "    return integral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrating quantitites along a straight line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if lensing_interpolations:\n",
    "    \n",
    "    #Defining starting and ending point for the integration, at two ends of a line on xy-plane\n",
    "    #Multiplying vertices by 0.99 to avoid asking for points outside the domain \n",
    "    starting_point = np.array([0, 0, domain_size*0.99])\n",
    "    ending_point = np.array([0, 0, -domain_size*0.99])\n",
    "\n",
    "    #using the line_integral function defined above\n",
    "    potential_integrated = line_integral(u, starting_point, ending_point, n=100)\n",
    "\n",
    "    #Integrating all components of the lensing Jacobian\n",
    "    lensing_jacobian_integrated_list = ([line_integral(component,starting_point,ending_point,n=100)\n",
    "                                   for component in lensing_jacobian_project_list])\n",
    "\n",
    "    #Putting the list in matrix form, can be handier to access\n",
    "    lensing_jacobian_integrated_matrix = np.reshape(lensing_jacobian_integrated_list,(3,3))\n",
    "\n",
    "    #We only need the Jacobian in a plane. In our case, our integration path given by starting_point\n",
    "    #and ending_point is along the z axis, so we're interested in the xy Jacobian, [0:1,0:1]\n",
    "    lensing_jacobian_xy_plane = lensing_jacobian_integrated_matrix[0:2, 0:2]\n",
    "\n",
    "    #We now obtain the quantities needed for the lensing formalism as described at:\n",
    "    #https://en.wikipedia.org/wiki/Gravitational_lensing_formalism#Lensing_Jacobian\n",
    "\n",
    "    #First, the distance between observer and lens. We set the observer and source to be the \n",
    "    #starting and end_points\n",
    "    observer_lens_Dd = domain_size\n",
    "\n",
    "    #Then, distance between source and lens\n",
    "    source_lens_Dds = domain_size\n",
    "\n",
    "    #And the overall distance between source and observer\n",
    "    source_observer_Ds = observer_lens_Dd + source_lens_Dds\n",
    "\n",
    "    #Now we find the Jacobian in the xy plane\n",
    "    jacobian_xy_plane_A = (np.eye(2) - 2*source_lens_Dds/(observer_lens_Dd*source_observer_Ds*c**2)*\n",
    "                           lensing_jacobian_xy_plane)\n",
    "\n",
    "    #PROBLEM: The value of the Jacobian for the current values is too small, so subtracting the\n",
    "    #small number from 1 returns 1! Need to find a way of working with more precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting radially\n",
    "## First, the potential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a function to compute the sum of the individual contributions from the analytic form so we can compare them to the overall solution we get from the PDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "potential_individual_diracs = 0\n",
    "\n",
    "for coordinates in random_coordinates:\n",
    "\n",
    "    #Obtaining the sorted coordinates for each source from random coordinates\n",
    "    V, vertex_number, x_coords, y_coords, z_coords, r_coords, sorting_index, x_sorted, y_sorted, z_sorted, r_sorted = rearrange_mesh_data(mesh, coordinates)\n",
    "\n",
    "    potential_individual_diracs = potential_individual_diracs + sqrt(G*mgb*a0)*np.log(r_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_individual_contributions(mesh, origin, coordinates):\n",
    "    '''Summing individual contributions of each source linearly'''\n",
    "    \n",
    "    #Initialising the sum for the potentials to be 0, then add each contribution to it from each source\n",
    "    potential_off_center = 0\n",
    "    \n",
    "    #Setting the distances to be from the origin so we have the same coordinates for all individual potential\n",
    "    #and we can coherently add them together\n",
    "    V, vertex_number, x_coords, y_coords, z_coords, r_coords, sorting_index, x_sorted, y_sorted, z_sorted, r_sorted = rearrange_mesh_data(mesh, origin)\n",
    "    \n",
    "    #Assigning each coordinate from the array given as input\n",
    "    coordinates_x = coordinates[:,0]\n",
    "    coordinates_y = coordinates[:,1]\n",
    "    coordinates_z = coordinates[:,2]\n",
    "    \n",
    "    #Summing over each source\n",
    "    for i in range(len(coordinates_x)):\n",
    "    \n",
    "        #Defining the potential with respect to a displaced source, but with the usual coordinates\n",
    "        potential_off_center += (sqrt(G*source_mass*a0)*1/2*np.log((x_coords-coordinates_x[i])**2+\n",
    "                    (y_coords-coordinates_y[i])**2 + (z_coords-coordinates_z[i])**2))\n",
    "    \n",
    "    return potential_off_center\n",
    "\n",
    "potential_individual_sum = sum_individual_contributions(mesh, origin, random_coordinates)\n",
    "\n",
    "type(potential_individual_sum)\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "# plt.scatter(x_coords, potential_individual_sum, s = 0.1)\n",
    "plt.scatter(x_coords, potential, s=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "radial_plots_start = time.time()\n",
    "\n",
    "#Defining analytic functions to check if the result is correct\n",
    "#2nd argument of Heaviside is its value where the Heaviside goes from 0 to 1\n",
    "potential_sphere_analytic = (np.heaviside(r_sorted - radius_tot, 0.5)*sqrt(G*mgb*a0)*np.log(r_sorted) +\n",
    "(np.heaviside(radius_tot - r_sorted, 0.5))*(4/3*sqrt(pi/3*a0*G*mgb/volume_out)*np.power(r_sorted,3/2)+\n",
    "sqrt(G*mgb*a0)*ln(radius_tot) - 4/3*sqrt(pi/3*a0*G*mgb/volume_out)*radius_tot**(3/2)))\n",
    "\n",
    "#Analytic potential on the inside of a sphere\n",
    "potential_inside_analytic = (4/3*sqrt(pi/3*a0*G*mgb/volume_out)*3/2*np.power(r_sorted,3/2)+\n",
    "sqrt(G*mgb*a0)*ln(radius_tot) - 4/3*sqrt(pi/3*a0*G*mgb/volume_out)*3/2*radius_tot**(3/2))\n",
    "\n",
    "#Analytic potential for a Dirac Delta\n",
    "potential_dirac_analytic = sqrt(G*mgb*a0)*np.log(r_sorted)\n",
    "\n",
    "#Analytic potential for multiple sources (scales with sqrt(#masses))\n",
    "potential_multiple_dirac_analytic = sqrt(G*mgb*a0/source_number)*np.log(r_sorted)\n",
    "\n",
    "#Analytic potentials for isothermal distribution\n",
    "potential_isothermal_analytic = 2/3*sqrt(G*mgb*a0/6)*np.log(1 + np.power(r_sorted, 3/2)/p**(3/2))\n",
    "\n",
    "#Plotting radial FEM solution and analytic solution on the same plot. We use subplots so'\n",
    "#we can put multiple axes on the same plot and plot different scales\n",
    "fig, potential1 = plt.subplots(sharex=True, sharey=True)\n",
    "\n",
    "color = 'tab:red'\n",
    "potential1.set_ylabel('FEM', color=color)\n",
    "\n",
    "potential1.plot(r_sorted, potential_sorted, label = 'FEM', color=color, linestyle='-')\n",
    "\n",
    "#Plotting the GEA potential as well\n",
    "# potential1.plot(r_sorted, potential_GEA_sorted, label = 'FEM_GEA', color='tab:green', linestyle='--', linewidth=0.5)\n",
    "\n",
    "potential1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "#UNCOMMENT TO HAVE SEPARATE AXES TO COMPARE SHAPES\n",
    "# potential2 = potential1.twinx()\n",
    "color = 'tab:blue'\n",
    "# potential2.set_ylabel('Analytic', color=color)\n",
    "plt.plot(r_sorted, potential_multiple_dirac_analytic, label = 'Dirac Analytic', linestyle = '--', )\n",
    "# potential2.plot(r_sorted, potential_sphere_analytic, label = 'Dirac Analytic', linestyle = '--', color=color)\n",
    "\n",
    "#It is possible to use Latex directly in the labels by enclosing expressions in $$\n",
    "# plt.ylabel('$\\phi$')\n",
    "\n",
    "plot_annotations(potential1)\n",
    "\n",
    "#Formatting plot using the function I made\n",
    "plot_format(potential1,1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the error in the potential, radially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for spherically symmetric mass distributions we have the anlytic solution, so we can compute\n",
    "#the error\n",
    "potential_error = np.abs((potential_sorted - potential_dirac_analytic)/potential_sorted)\n",
    "potential_proportionality = potential_dirac_analytic/potential_sorted\n",
    "\n",
    "#plotting the error against the radius\n",
    "fig, plot_potential_error = plt.subplots(sharex=True, sharey=True)\n",
    "plot_potential_error.plot(r_sorted,potential_error, label = 'Relative Error')\n",
    "plot_potential_error.plot(r_sorted,potential_proportionality, label = 'Proportionality')\n",
    "plt.title('Error in the Potential')\n",
    "plot_annotations(plot_potential_error)\n",
    "plot_format(plot_potential_error,1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking at the value of the potential along a specific axis. Useful when dealing with a non-radially symmetric distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.scatter(x_coords, potential, marker = '.', s = 0.5, c = y_coords/y_coords.max(), cmap = 'jet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next, the acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Defining analytic functions to check if the result is correct\n",
    "#2nd argument of Heaviside is its value where the Heaviside goes from 0 to 1\n",
    "acceleration_sphere_analytic = (np.heaviside(r_sorted - radius_tot, 0.5)*sqrt(G*mgb*a0)*1/r_sorted+\n",
    "(np.heaviside(radius_tot-r_sorted, 0.5))*4/3*sqrt(pi/3*a0*G*mgb/volume_out)*3/2*np.sqrt(r_sorted))\n",
    "\n",
    "acceleration_dirac_analytic = sqrt(G*mgb*a0)*1/r_sorted\n",
    "\n",
    "fig, acceleration1 = plt.subplots()\n",
    "\n",
    "color = 'tab:red'\n",
    "acceleration1.set_ylabel('FEM', color=color)\n",
    "\n",
    "acceleration1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "#Plotting radial FEM solution and analytic solution on the same plot\n",
    "acceleration1.plot(r_sorted, acceleration_magnitude_sorted, label = 'FEM', color = color)\n",
    "\n",
    "#UNCOMMENT TO HAVE SEPARATE Y AXES\n",
    "# acceleration2 = acceleration1.twinx()\n",
    "color = 'tab:blue'\n",
    "# acceleration2.set_ylabel('Analytic', color=color)\n",
    "\n",
    "plt.plot(r_sorted, acceleration_sphere_analytic, label = 'Analytic', linestyle = '--', color = color)\n",
    "plt.title('Gravitational Acceleration')\n",
    "\n",
    "plot_annotations(acceleration1)\n",
    "\n",
    "#Formatting plot using the function I made\n",
    "plot_format(acceleration1,1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the error in the acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for spherically symmetric mass distributions we have the anlytic solution, so we can compute\n",
    "#the error\n",
    "acceleration_error = np.abs((acceleration_magnitude_sorted - acceleration_dirac_analytic)/acceleration_magnitude_sorted)\n",
    "\n",
    "#plotting the error against the radius\n",
    "fig, acceleration_error_plot = plt.subplots()\n",
    "acceleration_error_plot.plot(r_sorted,acceleration_error, label = 'Relative Error')\n",
    "plt.title('Error in the Acceleration')\n",
    "plot_annotations(acceleration_error_plot)\n",
    "plot_format(acceleration_error_plot,1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the actual mass distribution that we input in the PDE, correpsonding to the baryonic matter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, source_radial_plot = plt.subplots()\n",
    "\n",
    "#Scaling the mass distribution by 4*pi*G to get rho itself\n",
    "source_radial_plot.plot(r_sorted, 1/(4*pi*G)*source_sorted)\n",
    "\n",
    "plt.title('Source')\n",
    "plot_annotations(source_radial_plot)\n",
    "plot_format(source_radial_plot,1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the laplacian of the solution, that for MOND corresponds to the total matter distribution, baryons+dark matter. For Newton it should correspond to the mass distribution that we input in the PDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, apparent_mass_plot = plt.subplots()\n",
    "\n",
    "plot_together = True\n",
    "\n",
    "#Scaling the mass distribution by 4*pi*G to get rho itself\n",
    "apparent_mass_plot.plot(r_sorted, 1/(4*pi*G)*apparent_mass_distribution_sorted, label = 'Apparent Mass Distribution')\n",
    "\n",
    "if plot_together == True:\n",
    "    \n",
    "    apparent_mass_plot.plot(r_sorted, 1/(4*pi*G)*source_sorted, label = 'Baryonic Mass Distribution', linestyle='--')\n",
    "\n",
    "plt.title('Apparent Mass Distribution')\n",
    "plot_annotations(apparent_mass_plot)\n",
    "plot_format(apparent_mass_plot,1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the difference between the apparent mass distribution obtained as the Laplacian of the solution, and the baryonic mass distribution which is the RHS of the PDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The difference between apparent mass and baryonic mass is the dark matter distribution\n",
    "dark_matter_density_sorted = (apparent_mass_distribution_sorted-source_sorted)\n",
    "\n",
    "fig, dark_matter_density_plot = plt.subplots()\n",
    "\n",
    "dark_matter_density_plot.plot(r_sorted, 1/(4*pi*G)*dark_matter_density_sorted)\n",
    "plt.title('Dark Matter Distribution')\n",
    "plot_annotations(dark_matter_density_plot)\n",
    "plot_format(dark_matter_density_plot,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#The ratio between apparent mass and baryonic mass is the dark matter distribution\n",
    "dark_matter_ratio_sorted = (apparent_mass_distribution_sorted/source_sorted)\n",
    "\n",
    "fig, dark_matter_ratio_plot = plt.subplots()\n",
    "\n",
    "dark_matter_ratio_plot.plot(r_sorted, dark_matter_ratio_sorted)\n",
    "plt.title('Dark Matter Ratio')\n",
    "plot_annotations(dark_matter_ratio_plot)\n",
    "plot_format(dark_matter_ratio_plot,1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram to look at the radial vertex distribution\n",
    "### First, defining the function to do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def radial_dist_hist(mesh, density, bins):\n",
    "    \n",
    "    #Having independent y axes so we don't need to adjust the function to compare the scaling \n",
    "    fig, histo = plt.subplots()\n",
    "    color = 'tab:blue'\n",
    "    histo.set_ylabel('radial distance density', color=color)\n",
    "    histo.tick_params(axis='y', labelcolor=color)\n",
    "    \n",
    "    #Looking at how the points are distributed radially. If they are uniform, their density\n",
    "    #should increase with r^2 due to sphere surface\n",
    "    #plotting histogram of point density radially\n",
    "    to_hist = histo.hist(r_coords, density=density, bins=bins, label = 'distribution', color = color)\n",
    "    \n",
    "    #Adding the value of each bin on top of the bin\n",
    "    for i in range(bins):\n",
    "        plt.text(to_hist[1][i],to_hist[0][i],str(int(to_hist[0][i])))\n",
    "    \n",
    "    #Putting the grid with the histogram values as those are the interesting quantities\n",
    "    plt.grid()\n",
    "    \n",
    "    #Second y axis\n",
    "    quadratic = histo.twinx()\n",
    "    color = 'tab:orange'\n",
    "    quadratic.set_ylabel('Quadratic', color=color)\n",
    "    quadratic.tick_params(axis='density', labelcolor=color)\n",
    "    \n",
    "    #plotting a cubic relation, scaled by the max element^3 to be of order unity\n",
    "    quadratic.plot(r_sorted, np.power(r_sorted,2), label = 'quadratic', color = color)\n",
    "    \n",
    "    #Forcing the lower limit in both plots to 0 so there's no offset\n",
    "    plt.ylim(bottom=0)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying the function to the generated mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radial_dist_hist(mesh, False, 10)\n",
    "\n",
    "radial_plots_end = time.time()\n",
    "radial_plots_time = run_time(radial_plots_start - radial_plots_end, 'Radial Plots')\n",
    "# section_times.append(radial_plots_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For non spherically symmetric meshes, and for visual clarity, taking a slice of the mesh and plotting it in 2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, a 3D view of the mesh vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mesh(figure, vertex_fraction, color, show_mesh = False, alpha = 0.3):\n",
    "    '''\n",
    "    Plotting the first vertex_number/vertex_fraction points of the mesh, based on radial\n",
    "    distance. Need to input a figure name of format figure = plt.figure() for the subplot\n",
    "    to work. Through this, we can embed this plot into other plots. Adding optional mesh and\n",
    "    alpha inputs.\n",
    "    '''\n",
    "    \n",
    "    #Getting the number of vertices required as an intege of the fraction given\n",
    "    how_many = int(vertex_number/vertex_fraction)\n",
    "    \n",
    "    #projection='3d' needed to specify a 3D scatter plot\n",
    "    mesh_scatter = figure.add_subplot(111, projection='3d')\n",
    "    \n",
    "    #plotting the total/vertex_fraction closest vertices to the origin\n",
    "    #s gives the size of the dots, multiplying it by vertex_fraction so when we have less dots\n",
    "    #we can make them more visible\n",
    "    (mesh_scatter.scatter(x_sorted[0:how_many], y_sorted[0:how_many], z_sorted[0:how_many],\n",
    "                         marker = '.', s=1*vertex_fraction, c = color))\n",
    "    \n",
    "    #Adding optional to show the mesh at the same time\n",
    "    if show_mesh:\n",
    "        plot(mesh, alpha = alpha, color = 'w')\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots_3D_start = time.time()\n",
    "\n",
    "#Have to first declare a figure and use its name as an input to the function\n",
    "#This way the plot can be plotted alongside other plots on the same grid\n",
    "whole_mesh = plt.figure()\n",
    "\n",
    "#Plotting the points \n",
    "plot_mesh(whole_mesh, 1, acceleration_magnitude_sorted, show_mesh=True, alpha = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining a slice of mesh points close to the xy plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_mesh(amount, mesh, height = 0, portion = True, values = True, *args):\n",
    "    '''Selecting only points of the mesh that are close to the xy plane. First, sorting points\n",
    "    according to their z coordinate, then selecting either amount # of them or a portion of the\n",
    "    total, dpeending on 'portion'. Optionally output a function args[0] at those points\n",
    "    '''\n",
    "    \n",
    "    #Getting abs(z), distance from xy plane, and getting the index that sorts this new array\n",
    "    xy_plane_distance = np.abs(z_coords - height)\n",
    "    \n",
    "    #index of points sorted by distance from xy plane (absolute value of z coordinate)\n",
    "    z_sorting_index = xy_plane_distance.argsort()\n",
    "    \n",
    "    #x,y,z coordinates of point sorted by distance from xy plane\n",
    "    z_xy_plane = z_coords[z_sorting_index]\n",
    "    x_xy_plane = x_coords[z_sorting_index]\n",
    "    y_xy_plane = y_coords[z_sorting_index]\n",
    "    \n",
    "    #If using the portion option, we take all points below a cutoff given by domain_size/amount\n",
    "    if portion == True:\n",
    "        \n",
    "        #counting number of points with xy_plane distance > domain_size/amount\n",
    "        amount = np.count_nonzero(xy_plane_distance < int(domain_size/amount))\n",
    "    \n",
    "    #If not using the portion option, the slice has num_vertices/amount total # points\n",
    "    else:\n",
    "        \n",
    "        amount = int(mesh.num_vertices()/amount)\n",
    "                \n",
    "    #The slice has amount # points\n",
    "    x_xy_plane = x_xy_plane[0:amount]\n",
    "    y_xy_plane = y_xy_plane[0:amount]\n",
    "    z_xy_plane = z_xy_plane[0:amount]\n",
    "\n",
    "    if values == True:\n",
    "        function_xy_plane = args[0][z_sorting_index]\n",
    "        function_xy_plane = function_xy_plane[0:amount]\n",
    "        \n",
    "        return x_xy_plane, y_xy_plane, z_xy_plane, function_xy_plane, amount\n",
    "    \n",
    "    else:\n",
    "        return x_xy_plane, y_xy_plane, z_xy_plane, amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mesh_slice(amount, figure, source_coordinates, height = 0, portion = True, show_mesh = True, cross_section = False, alpha = 0.3, show_source = True):\n",
    "    '''\n",
    "    Plotting a slice of points on the mesh close to the xy axis, so for small z.\n",
    "    Need to create a figure before calling the function. Optional showing mesh on top\n",
    "    of scatter, True by default, and transparency of mesh set by default to 0.3\n",
    "    '''\n",
    "    \n",
    "    #Calling the slice_mesh function to slice the mesh before plotting\n",
    "    x_xy_plane, y_xy_plane, z_xy_plane, amount = (slice_mesh(amount, mesh, height = height,\n",
    "                                                             portion = portion, values = False))\n",
    "    \n",
    "    #projection='3d' needed to specify a 3D scatter plot\n",
    "    mesh_xy_axis = figure.add_subplot(111, projection='3d')\n",
    "    \n",
    "    #plotting the total/vertex_fraction closest vertices to the origin\n",
    "    #s gives the size of the dots, multiplying it by vertex_fraction so when we have less dots\n",
    "    #we can make them more visible\n",
    "    (mesh_xy_axis.scatter(x_xy_plane, y_xy_plane, z_xy_plane,\n",
    "                         marker = '.', s=vertex_number/amount, c = z_xy_plane))\n",
    "    \n",
    "    #Plotting the source(s) on top of the mesh points, to check if we refine mesh correctly\n",
    "    if show_source == True:\n",
    "        \n",
    "        (mesh_xy_axis.scatter(random_coordinates[:,0],random_coordinates[:,1],\n",
    "        random_coordinates[:,2], marker = 'o', s=vertex_number/amount*5, c = 'r', label='Source'))\n",
    "            \n",
    "    \n",
    "    #Projecting each point on the xy plane, at z=0 (zs=0)\n",
    "    mesh_xy_axis.plot(x_xy_plane, y_xy_plane, 'b+', zdir='z', zs=height, label = 'xy-plane projection')\n",
    "    \n",
    "    mesh_xy_axis.legend()\n",
    "    \n",
    "    #Adding optional to show the mesh at the same time\n",
    "    if show_mesh:\n",
    "        plot(mesh, alpha = alpha, color = 'w')\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    #Option to plot the cross section, color coded by distance from xy plane\n",
    "    if cross_section:\n",
    "        plt.figure()\n",
    "        plt.scatter(x_xy_plane, y_xy_plane, c = z_xy_plane, marker = '+')\n",
    "        \n",
    "        if show_source:\n",
    "            (plt.scatter(random_coordinates[:,0],random_coordinates[:,1], marker = 'o',\n",
    "            color = 'r', s=vertex_number/amount*5))\n",
    "        \n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mesh_plane = plt.figure()\n",
    "plot_mesh_slice(20, mesh_plane, random_coordinates, height = center_of_mass_z, portion = True, cross_section=True, show_source=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a function to plot a trisurf graph of a slice of the domain, here the xy axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trisurf_function_slice(figure, function, amount, height, slices = 50, high_low = 'low', project = True):\n",
    "    '''Plot a trisurf along a plane (currently only the xy-plane) of a given function. The slice\n",
    "    of points defining the xy plane is obtained from the slice_mesh function. Then, project\n",
    "    the triangulated surface onto each axis if optional arg project = True. high_low determines\n",
    "    whether to project the xy plane contour above or below surface\n",
    "    '''\n",
    "    \n",
    "    #Obtaining the x,y coordinates and functions to plot from slice_mesh\n",
    "    x_xy_plane, y_xy_plane, z_xy_plane, function_xy_plane, amount = (slice_mesh(amount,\n",
    "                                            mesh, height, True, True, function))\n",
    "    \n",
    "    #Adding a subplot to the figure input\n",
    "    plane_trisurf = figure.add_subplot(111, projection='3d')\n",
    "    \n",
    "    #Plotting the trisurf (triangulated surface) on the plane\n",
    "    plane_trisurf.plot_trisurf(x_xy_plane, y_xy_plane, function_xy_plane, cmap = 'jet')\n",
    "    \n",
    "    #Setting the x and y limits to leave some space for the contours to be clearer\n",
    "    x_bottom, x_top = plt.xlim(-domain_size*1.2, domain_size*1.2) \n",
    "    y_bottom, y_top = plt.ylim(-domain_size*1.2, domain_size*1.2) \n",
    "    \n",
    "    #Setting the z limit conditionally, based on the function being increasing or decreasing\n",
    "    if high_low == 'high':\n",
    "        z_limit = function.max()\n",
    "    \n",
    "    else:\n",
    "        z_limit = function.min()\n",
    "    \n",
    "    #If project = True, project contours on each axis\n",
    "    if project:\n",
    "    \n",
    "        #Projecting contours of the surface in each cartesian direction using zdir and offset\n",
    "        #for direction and offset from the axes origins respectively\n",
    "        plane_trisurf.tricontourf(x_xy_plane, y_xy_plane, function_xy_plane, slices, zdir='z', offset=z_limit, cmap = 'jet')\n",
    "        plane_trisurf.tricontourf(x_xy_plane, y_xy_plane, function_xy_plane, slices, zdir='x', offset=y_bottom, cmap = 'jet')\n",
    "        plane_trisurf.tricontourf(x_xy_plane, y_xy_plane, function_xy_plane, slices, zdir='y', offset=x_top, cmap = 'jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_3D_graphs:\n",
    "\n",
    "    trisurf_potential = plt.figure()\n",
    "    trisurf_function_slice(trisurf_potential, potential, 20, center_of_mass_z)\n",
    "    plt.title('Potential in xy-plane')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_3D_graphs:  \n",
    "    \n",
    "    trisurf_acceleration = plt.figure()\n",
    "    trisurf_function_slice(trisurf_acceleration, acceleration_magnitude, 20, center_of_mass_z, high_low = 'high')\n",
    "    plt.title('Acceleration in xy-plane')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trisurf_source = plt.figure()\n",
    "# trisurf_function_slice(trisurf_source, source, 20, center_of_mass_z, high_low = 'high')\n",
    "# plt.title('Source in xy-plane')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting contour lines of the potential, so we can do that for different values of z and see the whole domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tricontour_function_slice(figure, function, amount, levels, height):\n",
    "    '''Plot a trisurf along a plane (currently only the xy-plane) of a given function. The slice\n",
    "    of points defining the xy plane is obtained from the slice_mesh function\n",
    "    '''\n",
    "    \n",
    "    #Obtaining the x,y coordinates and functions to plot from slice_mesh\n",
    "    x_xy_plane, y_xy_plane, z_xy_plane, function_xy_plane, amount = (slice_mesh(amount,\n",
    "                                            mesh, height, True, True, function))\n",
    "    \n",
    "    #Adding a subplot to the figure input. Not adding the projection = 3d option so we have it \n",
    "    #all in one plane and can plot multiple for e.g. different values of z\n",
    "    plane_tricontour = figure.add_subplot(111)\n",
    "    \n",
    "    #Defining the levels of the contour to be between the max and min value of the function\n",
    "    #in 'levels' homogeneous steps\n",
    "    contour_levels = np.linspace(function.min(), function.max(), levels)\n",
    "    \n",
    "    #Plotting the contour\n",
    "    plane_tricontour.tricontour(x_xy_plane, y_xy_plane, function_xy_plane, contour_levels, cmap = 'jet')\n",
    "    plane_tricontour.set_aspect('equal', 'box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tricontour_potential = plt.figure()\n",
    "tricontour_function_slice(tricontour_potential, potential, 20, 20, center_of_mass_z)\n",
    "plt.title('Potential in xy-plane')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trisurf_acceleration = plt.figure()\n",
    "tricontour_function_slice(trisurf_acceleration, acceleration_magnitude, 20, 20, center_of_mass_z)\n",
    "plt.title('Acceleration in xy-plane')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trisurf_source = plt.figure()\n",
    "tricontour_function_slice(trisurf_source, source, 20, 20, center_of_mass_z)\n",
    "plt.title('Source in xy-plane')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a function to plot slices and view them in 3D\n",
    "### The 2 cells below this on contain the call to the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contour_3D_slices(figure, function, amount, height, slices = 50, high_low = 'low'):\n",
    "    \n",
    "    #Adding a subplot to the figure input\n",
    "    plane_trisurf = figure.add_subplot(111, projection='3d')\n",
    "\n",
    "    #Setting the x and y limits to leave some space for the contours to be clearer\n",
    "    x_bottom, x_top = plt.xlim(-domain_size*1.2, domain_size*1.2) \n",
    "    y_bottom, y_top = plt.ylim(-domain_size*1.2, domain_size*1.2) \n",
    "#     z_bottom, z_top = Axes3D.zlim(-domain_size*1.2, domain_size*1.2) \n",
    "    \n",
    "    #Setting the z limit conditionally, based on the function being increasing or decreasing\n",
    "    if high_low == 'high':\n",
    "        z_limit = function.max()\n",
    "    \n",
    "    else:\n",
    "        z_limit = function.min()\n",
    "    \n",
    "    #Obtaining a range of n values for both the function and the domain (from min to max)\n",
    "    function_to_loop = np.linspace(function.min(), function.max(), 11)\n",
    "    height_to_loop = np.linspace(-domain_size*0.9, domain_size*0.9, 11)\n",
    "    \n",
    "    #Stacking the two ranges together so we can loop over them, and transpose so that each\n",
    "    #element of the array is a pair of corresponding function value-domain location\n",
    "    total_to_loop = np.vstack((function_to_loop, height_to_loop))\n",
    "    total_to_loop = np.transpose(total_to_loop)\n",
    "    \n",
    "    #Looping over the function-domain slice pairs\n",
    "    for elevations in total_to_loop:\n",
    "        \n",
    "        #IMPORTANT! For this loop to work, we need to have the same #function points for each\n",
    "        #slice. So we need to set the portion option from slice_mesh to False, so it takes\n",
    "        #the same #points every time, and not whatever number is within the given range\n",
    "        #Obtaining the x,y coordinates and functions to plot from slice_mesh\n",
    "        x_xy_plane, y_xy_plane, z_xy_plane, function_xy_plane, amount = (slice_mesh(amount,\n",
    "                                                mesh, elevations[1], False, True, function))\n",
    "\n",
    "        #Projecting contours of the surface in each cartesian direction using zdir and offset\n",
    "        #for direction and offset from the axes origins respectively\n",
    "        plane_trisurf.tricontourf(x_xy_plane, y_xy_plane, function_xy_plane, slices, zdir='z', offset=elevations[0],cmap = 'jet')\n",
    "    #     plane_trisurf.tricontourf(x_xy_plane, y_xy_plane, function_xy_plane, slices, zdir='x', offset=y_bottom, cmap = 'jet')\n",
    "    #     plane_trisurf.tricontourf(x_xy_plane, y_xy_plane, function_xy_plane, slices, zdir='y', offset=x_top, cmap = 'jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTANT: Right now, using a predefined amount of contours for each level, but this means\n",
    "#that the colors ar enot consistent between different levels! So want to change it that instead\n",
    "#of a numebr of contours, we have contours at specific values! That way the plot makes sense,\n",
    "#and it will also look like a sphere since the max potential will be at the boundary, which \n",
    "#becomes smaller for each level.\n",
    "\n",
    "# potential_slices = plt.figure()\n",
    "\n",
    "# contour_3D_slices(potential_slices, potential, 100, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acceleration_slices = plt.figure()\n",
    "\n",
    "# contour_3D_slices(acceleration_slices, acceleration_magnitude, 100, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source_slices = plt.figure()\n",
    "\n",
    "# contour_3D_slices(source_slices, source, 100, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at a quiver plot of the acceleration (useful when having multiple masses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure()\n",
    "\n",
    "quivers = figure.add_subplot(111, projection='3d')\n",
    "\n",
    "quivers.quiver(x_coords, y_coords, z_coords, acceleration_x, acceleration_y, acceleration_z, length=domain_size, normalize = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots_3D_end = time.time()\n",
    "plots_3D_time = run_time(plots_3D_end - plots_3D_start, '3D Plots')\n",
    "section_times.append(plots_3D_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the times taken by each section to profile the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "pie_name = [section.name for section in section_times]\n",
    "pie_time = np.zeros((len(section_times),1))\n",
    "\n",
    "#can't use a list comprehension as for pie_name to make a numpy array, cause it makes\n",
    "#a list instead! and for numbers it's always best to work with numpy \n",
    "for i, section in enumerate(section_times):\n",
    "    pie_time[i] = section.time\n",
    "    \n",
    "#percentage of time taken, to display on the pie chart\n",
    "pie_time_percent = [pie_time/(pie_time.sum()*100)]\n",
    "\n",
    "#plotting the pie chart\n",
    "plt.pie(pie_time, labels = pie_name)\n",
    "# plt.legend()\n",
    "plt.title('Computation Times per Section')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Overall time taken: {} s \\n'.format(time.time() - starting_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment to close all figures so it doesnt take up all the memory\n",
    "# plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other instance of main solver to either compare solutions or explore parameter space etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, we compare the three interpolation functions (deep, simple, standard) for some different mass distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def compare_solutions(PDE_List, max_value, variable_name, samples, variable_title, title_units):\n",
    "    '''This function accepts a list of BVP object, containing weak form, source, initial guess\n",
    "    and name for a given BVP. Max value is the maximum value of a variable that is to be analysed,\n",
    "    and looped over, variable_name is its name, samples is the amount of values to be taken between\n",
    "    zero and max_value when looping over the variable, and variable_title is used to name subplots'''\n",
    "    \n",
    "    print(f'{variable_name} = {eval(variable_name)}')\n",
    "    \n",
    "    #Defining the amount of subplots needed from the samples input. We want samples/2 columns, and 2 rows\n",
    "    #For it to work for odd numbers, we add the remainder of 2 so it's always divisible, then convert\n",
    "    #to integer\n",
    "    subplot_layout = (int((samples+samples%2)/2),2)\n",
    "    \n",
    "    #If we have only one sample, we make a plot with no subplots.\n",
    "    if samples == 1:\n",
    "    \n",
    "        fig, potential_compare = (plt.subplots(sharex=True,sharey=True))\n",
    "    \n",
    "    else: \n",
    "        \n",
    "        # Making a figure before we loop so all plots go in the same one. Sharing x,y axes per column/row\n",
    "        #and getting rid of space inbetween graphs\n",
    "        fig, potential_compare = (plt.subplots(subplot_layout[0],subplot_layout[1],sharex=True,sharey=True))\n",
    "    #                                           gridspec_kw={'hspace': 0, 'wspace': 0}))\n",
    "    \n",
    "    #Defining an empty list to hold the solutions of each PDE, with #elements equal to samples\n",
    "    u_list = [0 for sample in range(len(PDE_List))]\n",
    "\n",
    "    #Defining a list of the potentials from the solution from each weak form\n",
    "    potential_list = u_list\n",
    "\n",
    "    #List for the sorted potentials\n",
    "    potential_sorted_list = u_list\n",
    "    \n",
    "    #We loop over the chosen variable, going from its max_value/sample number to its max value\n",
    "    for j, variable_value in enumerate(np.linspace(1,samples,samples)*max_value/samples):\n",
    "        \n",
    "        #Assigning the value of variable_value to the variable (e.g. standard deviation, #source etc.)\n",
    "        #We need to evaluate it from here through te variable name in order for it to correctly pass it\n",
    "        #to the c++ code in the solver. {variable name}. Must use exec, not eval for assignment\n",
    "        exec(f'{variable_name} = {variable_value}')\n",
    "        \n",
    "        print(f'{variable_name} = {eval(variable_name)}')\n",
    "        \n",
    "        #If there are two or fewer subplots, the subplot index must actually be a number, not a tuple.\n",
    "        #Either 0 or 1, so same as j.\n",
    "        if samples <= 2:\n",
    "\n",
    "            subplot_index = j\n",
    "        \n",
    "        else:\n",
    "        \n",
    "            #Converting the index i to binary, then using it to indicate the subplots to use [0,0], [0,1]\n",
    "            # and so on\n",
    "            subplot_index = ((int(j/2), j%2))\n",
    "        \n",
    "        #Looping over weak forms for the same initial guess and source\n",
    "        for i, PDE in enumerate(PDE_List):\n",
    "            \n",
    "            #Putting the solutions in the u_list list\n",
    "            u_list[i], f = solve_PDE(PDE)\n",
    "\n",
    "            #Getting the potentials and sorted potentials for each solution\n",
    "            potential_list[i] = u_list[i].compute_vertex_values()\n",
    "            potential_sorted_list[i] = potential_list[i][sorting_index]\n",
    "            \n",
    "            #If we have the Newtonian potential, we add the difference at the boundary so they are on the\n",
    "            #same part of the plot. Doesnt matter that we add a constant to the potential anyway\n",
    "            if 'Newton' in PDE.name:\n",
    "                \n",
    "                potential_sorted_list[i] = (potential_sorted_list[i] + sqrt(G*mgb*a0)*ln(domain_size))\n",
    "            \n",
    "            #If we have only one sample, we plot on the plot itself, not a subplot\n",
    "            if samples == 1:\n",
    "                \n",
    "                #Plot all the potentials on the same graph\n",
    "                potential_compare.plot(r_sorted, potential_sorted_list[i], label = PDE.name)\n",
    "            \n",
    "            else:\n",
    "            \n",
    "                #Plot all the potentials on the same graph\n",
    "                potential_compare[subplot_index].plot(r_sorted, potential_sorted_list[i], label = PDE.name)\n",
    "        \n",
    "        #Making a string for the title of each plot. The :.2E is to format the number in the title to be\n",
    "        #in powers of 10.\n",
    "        plot_title = f'${variable_title} = {(int(variable_value)):.1E} \\: {title_units}$'\n",
    "        \n",
    "        #If we have only 1 sample, we need to call the function for the plot, rather than subplot\n",
    "        if samples == 1:\n",
    "        \n",
    "            #Giving a title to each subplot\n",
    "            potential_compare.set_title(plot_title)\n",
    "\n",
    "            #Formatting each subplot after it's been filled with all the curves\n",
    "            plot_format(potential_compare,1,1)\n",
    "        \n",
    "        else:\n",
    "\n",
    "            potential_compare[subplot_index].set_title(plot_title)\n",
    "\n",
    "            plot_format(potential_compare[subplot_index],1,1)\n",
    "        \n",
    "    return u_list, potential_sorted_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Lists of same source, different weak form.\n",
    "BVP_dirac_list = [newton_dirac, mond_deep_dirac, mond_simple_dirac, mond_standard_dirac]\n",
    "BVP_gauss_list = [newton_gauss, mond_deep_gauss, mond_simple_gauss, mond_standard_gauss]\n",
    "BVP_continuous_list = [newton_continuous, mond_deep_continuous, mond_simple_continuous, mond_standard_continuous]\n",
    "\n",
    "#list of same weak form, different source.\n",
    "BVP_deep_list = [mond_deep_dirac, mond_deep_gauss, mond_deep_continuous]\n",
    "BVP_simple_list = [mond_simple_dirac, mond_simple_gauss, mond_simple_continuous]\n",
    "BVP_standard_list = [mond_standard_dirac, mond_standard_gauss, mond_standard_continuous]\n",
    "BVP_newton_list = [newton_dirac, newton_gauss, newton_continuous]\n",
    "\n",
    "if make_comparison:\n",
    "\n",
    "    #Running the compare function\n",
    "    discrete_list = compare_solutions(BVP_dirac_list, stand_dev, 'stand_dev', 1, '\\sigma = ', 'Mpc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BVP_continuous_list[2].source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = 1\n",
    "\n",
    "subplot_layout = (int((samples+samples%2)/2),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
