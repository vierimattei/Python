{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is process 0 out of 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dolfin import *\n",
    "\n",
    "#Importing MPI for parallel computing\n",
    "# from mpi4py import MPI\n",
    "\n",
    "# #Importing the PETSc module for parallel use\n",
    "# from petsc4py import PETSc\n",
    "\n",
    "#importing mshr for all mesh functions\n",
    "import mshr as mshr\n",
    "\n",
    "# Use SymPy to compute f from the manufactured solution u\n",
    "import sympy as sym\n",
    "\n",
    "#Option to avoid printing redundant information from each core when running the code in parallel from\n",
    "#a python (.py) script obtained from the jupyter notebook.\n",
    "# parallel_run = True\n",
    "\n",
    "#MPI communicator\n",
    "comm = MPI.comm_world\n",
    "\n",
    "#Rank of each process (its ID essentially)\n",
    "rank = MPI.rank(comm)\n",
    "\n",
    "#Total number of processes\n",
    "number_processes = MPI.size(comm)\n",
    "\n",
    "print(f'This is process {rank} out of {number_processes-1}')\n",
    "\n",
    "if number_processes <2:\n",
    "\n",
    "    #Increasing the width of the notebook (visual difference only)\n",
    "    from IPython.core.display import display, HTML\n",
    "    display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "    \n",
    "    #have to define where to put plots BEFORE importing matplotlib\n",
    "    %matplotlib notebook\n",
    "\n",
    "#Importing matplotlib to plot the results\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#Importing numpy to work with arrays\n",
    "import numpy as np\n",
    "\n",
    "#Importing time to compute how long each segment takes\n",
    "import time\n",
    "\n",
    "#importing regex to change every instance of radius_tot so we change the ones in the C++ code\n",
    "#at the same time too\n",
    "import re\n",
    "\n",
    "#varname gives the name of the variable as a string\n",
    "from varname import varname\n",
    "\n",
    "#Needed to use the 3D scatter\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "#Importing the decimal package to be able to specify arbitrary accuracy, needed e.g. when\n",
    "#calculating the jacobian for the lensing\n",
    "from decimal import *\n",
    "\n",
    "#Importing all quantities, constants etc used in the calculations\n",
    "from MONDquantities import *\n",
    "\n",
    "#Importing all classes I created\n",
    "from MONDclasses import *\n",
    "\n",
    "#Importing the functions I made from the MONDfunctions file\n",
    "from MONDfunctions import *\n",
    "\n",
    "#Importing all expressions for weak forms, initial guesses/BCs and sources\n",
    "from MONDexpressions import *\n",
    "\n",
    "#Needed if want to use the adapt function for mesh refinement, see:\n",
    "#https://fenicsproject.org/qa/6719/using-adapt-on-a-meshfunction-looking-for-a-working-example/\n",
    "#If using 'plaza' instead of 'plaza_with_parent_facets', it's faster by about 30%!\n",
    "parameters[\"refinement_algorithm\"] = \"plaza\"\n",
    "\n",
    "#ParMETIS is optimised to partition the mesh in parallel. SCOTCH is the default I used for serial\n",
    "#ParMETIS: http://glaros.dtc.umn.edu/gkhome/metis/parmetis/overview. Unfortunately Dolfin wasnt\n",
    "#built with ParMETIS so i cant use it.\n",
    "parameters['mesh_partitioner'] = 'SCOTCH'\n",
    "\n",
    "#Setting compiler parameters.\n",
    "#Optimisation\n",
    "parameters[\"form_compiler\"][\"optimize\"]     = True\n",
    "parameters[\"form_compiler\"][\"cpp_optimize\"] = True\n",
    "\n",
    "#Ghost mode for when using MPI. Each process gets ghost vertices for the part of the domain it does not\n",
    "#own. Have to set to 'none' instead or I get Error 'Unable to create BoundaryMesh with ghost cells.'\n",
    "parameters['ghost_mode'] = 'none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info(parameters,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting mesh generation...\n",
      "\n",
      "Mesh generated in 2.677976608276367 s \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## starting time of whole PDE solver\n",
    "starting_time = time.time()\n",
    "\n",
    "#starting an empty list to contain all of the run_time objects to plot later\n",
    "section_times = []\n",
    "\n",
    "print('Starting mesh generation...\\n')\n",
    "mesh_generation_start = time.time()\n",
    "\n",
    "#Making mesh from function defined above\n",
    "mesh = make_spherical_mesh(domain_size, mesh_resolution)\n",
    "\n",
    "mesh_generation_end = time.time()\n",
    "mesh_generation_time = run_time(mesh_generation_end - mesh_generation_start, 'Mesh Generation')\n",
    "section_times.append(mesh_generation_time)\n",
    "print('Mesh generated in {} s \\n'.format(mesh_generation_time.time))\n",
    "\n",
    "#Setting the MPI communicator for the mesh (doesnt seem to do anything right now)\n",
    "# mesh.mpi_comm = comm\n",
    "\n",
    "# print(f'Process {rank} says marmamamam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For all the points to be within a given radius, each coordinate must be smaller than\n",
    "#radius_population/sqrt(3)\n",
    "random_max_distance = radius_population/sqrt(3)\n",
    "\n",
    "#Setting a given seed so we can always have the same random numbers for now\n",
    "np.random.seed(1)\n",
    "\n",
    "#We want a mean of 0 so center of mass is in center, and the same standard deviation as the gaussian\n",
    "#pulse. This means we sample from the same distribution as the smooth one, and have the same mean.\n",
    "#This is exactly what we want to compare coarse and smooth distributions\n",
    "mu, sigma = 0, stand_dev\n",
    "random_coordinates_x = np.random.normal(mu, sigma, source_number)\n",
    "random_coordinates_y = np.random.normal(mu, sigma, source_number)\n",
    "\n",
    "#If we want all source to be in the same plane, we set the z axis to be 0 for all of them. Otherwise,\n",
    "#random as above\n",
    "if coplanar_sources == True:\n",
    "    \n",
    "    random_coordinates_z = np.zeros((source_number, 1)).ravel()\n",
    "\n",
    "else:\n",
    "    \n",
    "    random_coordinates_z = np.random.normal(mu, sigma, source_number)\n",
    "\n",
    "#If we dont need Gaussian, defining a source_number*3 array of random numbers between 0 and 1 and\n",
    "#multiplying by the radius just defined so all points are inside a sphere of radius_tot.\n",
    "#Subtracting 0.5 so #we're sampling equally from the positive and negative instead of from 0 to 1\n",
    "# random_coordinates = random_max_distance * (np.random.rand(source_number, 3)-0.5)\n",
    "\n",
    "# Uncomment for test case with two equal masses on the xy plane at a given distance\n",
    "# their_distance = 3\n",
    "\n",
    "# # random_coordinates[0][0] = -domain_size/their_distance\n",
    "if central_mass:\n",
    "\n",
    "    random_coordinates_x[0] = 0\n",
    "    random_coordinates_y[0] = 0\n",
    "    random_coordinates_z[0] = 0\n",
    "\n",
    "# random_coordinates[1][0] = domain_size/their_distance\n",
    "# random_coordinates[1][1] = 0\n",
    "# random_coordinates[1][2] = 0\n",
    "\n",
    "#Overall array containing all coordinates. If over-writing the random position, this has to go after it,\n",
    "#otherwise the c++ array for the source sets the wrong position!\n",
    "random_coordinates = np.array((random_coordinates_x, random_coordinates_y, random_coordinates_z))\n",
    "random_coordinates = np.transpose(random_coordinates)\n",
    "\n",
    "#Obtaining the center of each source as a list of points\n",
    "source_centers = [Point(random_coordinates_x[i], random_coordinates_y[i], random_coordinates_z[i]) for i in range(source_number)]\n",
    "\n",
    "len(source_centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting mesh refinement...\n",
      "\n",
      "The submesh of process 0 has 21302 cells\n",
      "Process 0's cell_containing is: [1173]\n",
      "Iteration 1 of 6: The Cell number went from 21302 to 21410, up by a factor 1.0050699464838981\n",
      "\n",
      "Iteration 2 of 6: The Cell number went from 21410 to 21872, up by a factor 1.0215787015413358\n",
      "\n",
      "Iteration 3 of 6: The Cell number went from 21872 to 22403, up by a factor 1.024277615215801\n",
      "\n",
      "Iteration 4 of 6: The Cell number went from 22403 to 22945, up by a factor 1.0241931884122661\n",
      "\n",
      "Iteration 5 of 6: The Cell number went from 22945 to 23493, up by a factor 1.0238831989540205\n",
      "\n",
      "Iteration 6 of 6: The Cell number went from 23493 to 24430, up by a factor 1.0398842208317371\n",
      "\n",
      "Cell number went up by a factor 1.1468406722373485\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Starting mesh refinement...\\n')\n",
    "mesh_refine_start = time.time()\n",
    "\n",
    "\n",
    "#Finding the #cells in each mesh, so if the ID of the collision is larger than the # cells, we are sure\n",
    "#that submesh doesnt contain that point.\n",
    "number_cells = mesh.num_cells()\n",
    "\n",
    "print(f'The submesh of process {rank} has {number_cells} cells')\n",
    "\n",
    "cell_containing = intersect(mesh, source_centers[0]).intersected_cells()\n",
    "\n",
    "print(f'Process {rank}\\'s cell_containing is: {cell_containing}')\n",
    "\n",
    "#We only want to refine the submesh if it contains the point. If it doesnt contain the point, the list\n",
    "#cell_containing will be empty! We can check this by the length of the list .If the list has length\n",
    "#0 that means that submesh doesn't include the point! \n",
    "#The reason the function was giving problems to begin with is that we were trying to index that list\n",
    "#that had zero elements in it, so the 0th element was already too large an index and was out of range!\n",
    "\n",
    "how_many = refine_times\n",
    "\n",
    "#Starting # cells before we refine, to compute growth factor\n",
    "starting_cells = mesh.num_cells()\n",
    "\n",
    "for i in range(how_many):\n",
    "\n",
    "    #Declaring Boolean Mesh Function to individuate cell containing point\n",
    "    contain_function = MeshFunction(\"bool\", mesh, 3)\n",
    "\n",
    "    #Setting function to False everywhere\n",
    "    contain_function.set_all(False)\n",
    "\n",
    "    #Initial number of cells before refinement\n",
    "    initial_cells = mesh.num_cells()\n",
    "\n",
    "    #List comprehension containing the cell IDs for the cells containing a source\n",
    "    #The if statement make sure that the intersect_list is only populated for points\n",
    "    #that are inside the mesh. For parallel, where the mesh is split, this is necessary!\n",
    "    intersect_list = [intersect(mesh, source).intersected_cells() for source in source_centers]\n",
    "\n",
    "    #Setting the cell function contain_function to true for each cell containing a source\n",
    "    for cell_index in intersect_list:\n",
    "\n",
    "        #For MPI, the intersect_list might be empty in case the point is not inside the \n",
    "        #submesh! So we first need to check that there's an element present. If we don't\n",
    "        #we'll get an error about index out of range cause index 0 is out of range for an\n",
    "        #empty list!\n",
    "        if not len(cell_index) == 0: \n",
    "\n",
    "            contain_function[cell_index[0]] = True\n",
    "\n",
    "    #Refining the mesh only for cells that contain a source\n",
    "    mesh = refine(mesh, contain_function, redistribute=True)    \n",
    "\n",
    "    #Final # cells after refinement\n",
    "    final_cells = mesh.num_cells()\n",
    "\n",
    "    partial_growth_factor = final_cells/initial_cells\n",
    "\n",
    "    print(('Iteration {} of {}: The Cell number went from {} to {}, up by a factor {}\\n'\n",
    "          .format(i+1, how_many, initial_cells, final_cells, partial_growth_factor)))\n",
    "\n",
    "#ratio between # cells at beginning and end of refinement\n",
    "total_growth_factor = final_cells/starting_cells\n",
    "\n",
    "print('Cell number went up by a factor {}\\n'.format(total_growth_factor))\n",
    "\n",
    "# cell_containing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking if computing the collision with the bounding box tree is faster than checking if point is\n",
    "#inside a cell\n",
    "\n",
    "# mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#See this link: https://fenicsproject.org/qa/12431/reading-hdf5-file-with-fenics-2016-2/\n",
    "\n",
    "# meshname = 'parallel_mesh'\n",
    "\n",
    "# f = HDF5File(mesh.mpi_comm(), meshname+\".hdf5\", 'w')\n",
    "# f.write(mesh, meshname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mesh = Mesh()\n",
    "# f = HDF5File(MPI.comm_world, meshname+\"hdf5\", 'r')\n",
    "# f.read(mesh, meshname, False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
